{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aditya/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-640e33fe9da4>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /home/aditya/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /home/aditya/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From /home/aditya/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From /home/aditya/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/aditya/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /home/aditya/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 1000\n",
    "batch_size = 100\n",
    "\n",
    "num_inputs = 784\n",
    "num_classes =10\n",
    "dropout = 0.75\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape = [None, num_inputs])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides = [1, strides, strides, 1], padding = 'SAME')\n",
    "    x = tf.nn.bias_add(x,b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(x, k = 2):\n",
    "    return tf.nn.max_pool(x, ksize = [1,k,k,1], strides = [1, k, k, 1], padding = 'SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, bias, dropout):\n",
    "    x = tf.reshape(x, shape = [-1,28,28,1])\n",
    "    conv1 = conv2d(x, weights['l1'], bias['l1'])\n",
    "    conv1 = maxpool2d(conv1, 2)\n",
    "    \n",
    "    conv2 = conv2d(conv1, weights['l2'], bias['l2'])\n",
    "    conv2 = maxpool2d(conv2, 2)\n",
    "    \n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), bias['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    \n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), bias['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aditya/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "weights = {\n",
    "    'l1': tf.Variable(tf.random_normal([5,5,1,32])),\n",
    "    'l2': tf.Variable(tf.random_normal([5,5,32,64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out':tf.Variable(tf.random_normal([1024, num_classes]))\n",
    "}\n",
    "bias = {\n",
    "    'l1':tf.Variable(tf.random_normal([32])),\n",
    "    'l2':tf.Variable(tf.random_normal([64])),\n",
    "    'bd1':tf.Variable(tf.random_normal([1024])),\n",
    "    'out':tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aditya/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py:2744: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From <ipython-input-8-a0a0a1f61908>:5: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logits = conv_net(X, weights, bias, keep_prob)\n",
    "\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = 0.01).minimize(loss)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1..........Loss: 93782.90625...........Accuracy: 0.17000000178813934\n",
      "Epoch: 2..........Loss: 110047.2109375...........Accuracy: 0.20000000298023224\n",
      "Epoch: 3..........Loss: 101565.6875...........Accuracy: 0.2199999988079071\n",
      "Epoch: 4..........Loss: 80219.953125...........Accuracy: 0.23000000417232513\n",
      "Epoch: 5..........Loss: 49174.421875...........Accuracy: 0.38999998569488525\n",
      "Epoch: 6..........Loss: 46381.65625...........Accuracy: 0.44999998807907104\n",
      "Epoch: 7..........Loss: 51674.5390625...........Accuracy: 0.46000000834465027\n",
      "Epoch: 8..........Loss: 34472.328125...........Accuracy: 0.4699999988079071\n",
      "Epoch: 9..........Loss: 25210.130859375...........Accuracy: 0.5199999809265137\n",
      "Epoch: 10..........Loss: 25607.75...........Accuracy: 0.47999998927116394\n",
      "Epoch: 11..........Loss: 14247.103515625...........Accuracy: 0.5400000214576721\n",
      "Epoch: 12..........Loss: 14625.240234375...........Accuracy: 0.5600000023841858\n",
      "Epoch: 13..........Loss: 10328.1484375...........Accuracy: 0.5799999833106995\n",
      "Epoch: 14..........Loss: 7486.69873046875...........Accuracy: 0.5799999833106995\n",
      "Epoch: 15..........Loss: 3823.76416015625...........Accuracy: 0.699999988079071\n",
      "Epoch: 16..........Loss: 3412.784912109375...........Accuracy: 0.6800000071525574\n",
      "Epoch: 17..........Loss: 4901.6611328125...........Accuracy: 0.6600000262260437\n",
      "Epoch: 18..........Loss: 4369.79736328125...........Accuracy: 0.6700000166893005\n",
      "Epoch: 19..........Loss: 5348.201171875...........Accuracy: 0.6700000166893005\n",
      "Epoch: 20..........Loss: 5195.5400390625...........Accuracy: 0.5600000023841858\n",
      "Epoch: 21..........Loss: 3238.063232421875...........Accuracy: 0.6600000262260437\n",
      "Epoch: 22..........Loss: 2380.789794921875...........Accuracy: 0.75\n",
      "Epoch: 23..........Loss: 2919.41845703125...........Accuracy: 0.6600000262260437\n",
      "Epoch: 24..........Loss: 1349.716552734375...........Accuracy: 0.8600000143051147\n",
      "Epoch: 25..........Loss: 2006.64306640625...........Accuracy: 0.8399999737739563\n",
      "Epoch: 26..........Loss: 1453.9525146484375...........Accuracy: 0.8199999928474426\n",
      "Epoch: 27..........Loss: 1021.9882202148438...........Accuracy: 0.8700000047683716\n",
      "Epoch: 28..........Loss: 1102.080078125...........Accuracy: 0.8600000143051147\n",
      "Epoch: 29..........Loss: 2480.620849609375...........Accuracy: 0.7799999713897705\n",
      "Epoch: 30..........Loss: 2643.54931640625...........Accuracy: 0.8100000023841858\n",
      "Epoch: 31..........Loss: 1650.239013671875...........Accuracy: 0.7799999713897705\n",
      "Epoch: 32..........Loss: 2438.085693359375...........Accuracy: 0.7799999713897705\n",
      "Epoch: 33..........Loss: 1468.4862060546875...........Accuracy: 0.800000011920929\n",
      "Epoch: 34..........Loss: 1965.26171875...........Accuracy: 0.7699999809265137\n",
      "Epoch: 35..........Loss: 1319.47998046875...........Accuracy: 0.8700000047683716\n",
      "Epoch: 36..........Loss: 1118.1070556640625...........Accuracy: 0.8399999737739563\n",
      "Epoch: 37..........Loss: 507.9354553222656...........Accuracy: 0.9100000262260437\n",
      "Epoch: 38..........Loss: 1663.60791015625...........Accuracy: 0.8399999737739563\n",
      "Epoch: 39..........Loss: 911.4860229492188...........Accuracy: 0.800000011920929\n",
      "Epoch: 40..........Loss: 1569.1971435546875...........Accuracy: 0.7599999904632568\n",
      "Epoch: 41..........Loss: 663.2748413085938...........Accuracy: 0.8500000238418579\n",
      "Epoch: 42..........Loss: 1085.4208984375...........Accuracy: 0.8700000047683716\n",
      "Epoch: 43..........Loss: 876.9021606445312...........Accuracy: 0.8799999952316284\n",
      "Epoch: 44..........Loss: 635.5074462890625...........Accuracy: 0.8399999737739563\n",
      "Epoch: 45..........Loss: 993.052001953125...........Accuracy: 0.8600000143051147\n",
      "Epoch: 46..........Loss: 880.3987426757812...........Accuracy: 0.8199999928474426\n",
      "Epoch: 47..........Loss: 492.9434814453125...........Accuracy: 0.8600000143051147\n",
      "Epoch: 48..........Loss: 587.1943969726562...........Accuracy: 0.8799999952316284\n",
      "Epoch: 49..........Loss: 620.279541015625...........Accuracy: 0.9100000262260437\n",
      "Epoch: 50..........Loss: 458.3150634765625...........Accuracy: 0.8899999856948853\n",
      "Epoch: 51..........Loss: 516.17919921875...........Accuracy: 0.9200000166893005\n",
      "Epoch: 52..........Loss: 239.23585510253906...........Accuracy: 0.9200000166893005\n",
      "Epoch: 53..........Loss: 380.80926513671875...........Accuracy: 0.8999999761581421\n",
      "Epoch: 54..........Loss: 545.2620239257812...........Accuracy: 0.8500000238418579\n",
      "Epoch: 55..........Loss: 245.44357299804688...........Accuracy: 0.949999988079071\n",
      "Epoch: 56..........Loss: 445.9706115722656...........Accuracy: 0.8899999856948853\n",
      "Epoch: 57..........Loss: 306.7793273925781...........Accuracy: 0.9300000071525574\n",
      "Epoch: 58..........Loss: 604.714599609375...........Accuracy: 0.8999999761581421\n",
      "Epoch: 59..........Loss: 413.7013244628906...........Accuracy: 0.8899999856948853\n",
      "Epoch: 60..........Loss: 549.311767578125...........Accuracy: 0.8899999856948853\n",
      "Epoch: 61..........Loss: 179.29132080078125...........Accuracy: 0.949999988079071\n",
      "Epoch: 62..........Loss: 406.2050476074219...........Accuracy: 0.8399999737739563\n",
      "Epoch: 63..........Loss: 814.9793701171875...........Accuracy: 0.8799999952316284\n",
      "Epoch: 64..........Loss: 876.9338989257812...........Accuracy: 0.8700000047683716\n",
      "Epoch: 65..........Loss: 479.8731994628906...........Accuracy: 0.9200000166893005\n",
      "Epoch: 66..........Loss: 313.1413879394531...........Accuracy: 0.9300000071525574\n",
      "Epoch: 67..........Loss: 162.02244567871094...........Accuracy: 0.949999988079071\n",
      "Epoch: 68..........Loss: 364.8145751953125...........Accuracy: 0.9300000071525574\n",
      "Epoch: 69..........Loss: 617.6060791015625...........Accuracy: 0.8999999761581421\n",
      "Epoch: 70..........Loss: 436.6776428222656...........Accuracy: 0.8399999737739563\n",
      "Epoch: 71..........Loss: 372.2427978515625...........Accuracy: 0.9300000071525574\n",
      "Epoch: 72..........Loss: 313.41766357421875...........Accuracy: 0.8799999952316284\n",
      "Epoch: 73..........Loss: 107.72290802001953...........Accuracy: 0.9399999976158142\n",
      "Epoch: 74..........Loss: 321.8892517089844...........Accuracy: 0.8899999856948853\n",
      "Epoch: 75..........Loss: 570.337890625...........Accuracy: 0.9100000262260437\n",
      "Epoch: 76..........Loss: 635.185546875...........Accuracy: 0.8999999761581421\n",
      "Epoch: 77..........Loss: 313.9410095214844...........Accuracy: 0.9100000262260437\n",
      "Epoch: 78..........Loss: 389.1561279296875...........Accuracy: 0.9300000071525574\n",
      "Epoch: 79..........Loss: 344.8106689453125...........Accuracy: 0.9300000071525574\n",
      "Epoch: 80..........Loss: 239.83424377441406...........Accuracy: 0.9200000166893005\n",
      "Epoch: 81..........Loss: 421.65960693359375...........Accuracy: 0.9100000262260437\n",
      "Epoch: 82..........Loss: 431.9271545410156...........Accuracy: 0.8399999737739563\n",
      "Epoch: 83..........Loss: 690.7047729492188...........Accuracy: 0.8600000143051147\n",
      "Epoch: 84..........Loss: 160.37191772460938...........Accuracy: 0.949999988079071\n",
      "Epoch: 85..........Loss: 294.7081604003906...........Accuracy: 0.949999988079071\n",
      "Epoch: 86..........Loss: 302.1303405761719...........Accuracy: 0.8999999761581421\n",
      "Epoch: 87..........Loss: 452.679931640625...........Accuracy: 0.8999999761581421\n",
      "Epoch: 88..........Loss: 677.3682250976562...........Accuracy: 0.8799999952316284\n",
      "Epoch: 89..........Loss: 176.8896026611328...........Accuracy: 0.949999988079071\n",
      "Epoch: 90..........Loss: 449.3524169921875...........Accuracy: 0.8999999761581421\n",
      "Epoch: 91..........Loss: 34.97097396850586...........Accuracy: 0.9800000190734863\n",
      "Epoch: 92..........Loss: 184.96124267578125...........Accuracy: 0.9200000166893005\n",
      "Epoch: 93..........Loss: 254.4934539794922...........Accuracy: 0.8999999761581421\n",
      "Epoch: 94..........Loss: 235.29562377929688...........Accuracy: 0.9100000262260437\n",
      "Epoch: 95..........Loss: 265.93798828125...........Accuracy: 0.9100000262260437\n",
      "Epoch: 96..........Loss: 350.21734619140625...........Accuracy: 0.9399999976158142\n",
      "Epoch: 97..........Loss: 195.7248992919922...........Accuracy: 0.9300000071525574\n",
      "Epoch: 98..........Loss: 325.4423828125...........Accuracy: 0.9200000166893005\n",
      "Epoch: 99..........Loss: 180.99302673339844...........Accuracy: 0.949999988079071\n",
      "Epoch: 100..........Loss: 278.1661376953125...........Accuracy: 0.9300000071525574\n",
      "Epoch: 101..........Loss: 170.06085205078125...........Accuracy: 0.9300000071525574\n",
      "Epoch: 102..........Loss: 303.2493896484375...........Accuracy: 0.8999999761581421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 103..........Loss: 167.79234313964844...........Accuracy: 0.949999988079071\n",
      "Epoch: 104..........Loss: 180.76812744140625...........Accuracy: 0.9300000071525574\n",
      "Epoch: 105..........Loss: 272.8663330078125...........Accuracy: 0.9300000071525574\n",
      "Epoch: 106..........Loss: 217.7118682861328...........Accuracy: 0.949999988079071\n",
      "Epoch: 107..........Loss: 407.9804992675781...........Accuracy: 0.9100000262260437\n",
      "Epoch: 108..........Loss: 270.05584716796875...........Accuracy: 0.9399999976158142\n",
      "Epoch: 109..........Loss: 414.979248046875...........Accuracy: 0.9300000071525574\n",
      "Epoch: 110..........Loss: 73.87870788574219...........Accuracy: 0.9300000071525574\n",
      "Epoch: 111..........Loss: 302.68975830078125...........Accuracy: 0.9200000166893005\n",
      "Epoch: 112..........Loss: 435.1524963378906...........Accuracy: 0.8799999952316284\n",
      "Epoch: 113..........Loss: 494.716552734375...........Accuracy: 0.8799999952316284\n",
      "Epoch: 114..........Loss: 184.73411560058594...........Accuracy: 0.9599999785423279\n",
      "Epoch: 115..........Loss: 92.42143249511719...........Accuracy: 0.9599999785423279\n",
      "Epoch: 116..........Loss: 281.1009216308594...........Accuracy: 0.9200000166893005\n",
      "Epoch: 117..........Loss: 294.9452819824219...........Accuracy: 0.8999999761581421\n",
      "Epoch: 118..........Loss: 211.8725128173828...........Accuracy: 0.9300000071525574\n",
      "Epoch: 119..........Loss: 277.5400085449219...........Accuracy: 0.9100000262260437\n",
      "Epoch: 120..........Loss: 98.73360443115234...........Accuracy: 0.949999988079071\n",
      "Epoch: 121..........Loss: 752.0560302734375...........Accuracy: 0.8899999856948853\n",
      "Epoch: 122..........Loss: 162.24229431152344...........Accuracy: 0.9399999976158142\n",
      "Epoch: 123..........Loss: 483.572509765625...........Accuracy: 0.8999999761581421\n",
      "Epoch: 124..........Loss: 444.4278564453125...........Accuracy: 0.8700000047683716\n",
      "Epoch: 125..........Loss: 344.1187438964844...........Accuracy: 0.9100000262260437\n",
      "Epoch: 126..........Loss: 490.744140625...........Accuracy: 0.8700000047683716\n",
      "Epoch: 127..........Loss: 341.6011962890625...........Accuracy: 0.9200000166893005\n",
      "Epoch: 128..........Loss: 241.0342254638672...........Accuracy: 0.9399999976158142\n",
      "Epoch: 129..........Loss: 179.2458953857422...........Accuracy: 0.9300000071525574\n",
      "Epoch: 130..........Loss: 467.8853454589844...........Accuracy: 0.8799999952316284\n",
      "Epoch: 131..........Loss: 439.4346618652344...........Accuracy: 0.8700000047683716\n",
      "Epoch: 132..........Loss: 180.27874755859375...........Accuracy: 0.9200000166893005\n",
      "Epoch: 133..........Loss: 175.03125...........Accuracy: 0.9399999976158142\n",
      "Epoch: 134..........Loss: 57.94794845581055...........Accuracy: 0.9900000095367432\n",
      "Epoch: 135..........Loss: 92.5634765625...........Accuracy: 0.9700000286102295\n",
      "Epoch: 136..........Loss: 575.0946044921875...........Accuracy: 0.8999999761581421\n",
      "Epoch: 137..........Loss: 253.17620849609375...........Accuracy: 0.9399999976158142\n",
      "Epoch: 138..........Loss: 83.62287139892578...........Accuracy: 0.9399999976158142\n",
      "Epoch: 139..........Loss: 193.38328552246094...........Accuracy: 0.9300000071525574\n",
      "Epoch: 140..........Loss: 143.00564575195312...........Accuracy: 0.9700000286102295\n",
      "Epoch: 141..........Loss: 179.0831298828125...........Accuracy: 0.9399999976158142\n",
      "Epoch: 142..........Loss: 212.7963104248047...........Accuracy: 0.949999988079071\n",
      "Epoch: 143..........Loss: 99.01094055175781...........Accuracy: 0.9100000262260437\n",
      "Epoch: 144..........Loss: 73.0832290649414...........Accuracy: 0.9399999976158142\n",
      "Epoch: 145..........Loss: 191.2567138671875...........Accuracy: 0.9100000262260437\n",
      "Epoch: 146..........Loss: 148.63853454589844...........Accuracy: 0.9300000071525574\n",
      "Epoch: 147..........Loss: 318.2735595703125...........Accuracy: 0.8999999761581421\n",
      "Epoch: 148..........Loss: 42.87321472167969...........Accuracy: 0.9700000286102295\n",
      "Epoch: 149..........Loss: 103.6854476928711...........Accuracy: 0.9599999785423279\n",
      "Epoch: 150..........Loss: 38.8065185546875...........Accuracy: 0.949999988079071\n",
      "Epoch: 151..........Loss: 168.8986358642578...........Accuracy: 0.9100000262260437\n",
      "Epoch: 152..........Loss: 233.2780303955078...........Accuracy: 0.9300000071525574\n",
      "Epoch: 153..........Loss: 223.73800659179688...........Accuracy: 0.9200000166893005\n",
      "Epoch: 154..........Loss: 271.34326171875...........Accuracy: 0.9100000262260437\n",
      "Epoch: 155..........Loss: 105.92291259765625...........Accuracy: 0.949999988079071\n",
      "Epoch: 156..........Loss: 178.4195098876953...........Accuracy: 0.9300000071525574\n",
      "Epoch: 157..........Loss: 15.442329406738281...........Accuracy: 0.9800000190734863\n",
      "Epoch: 158..........Loss: 96.57211303710938...........Accuracy: 0.9399999976158142\n",
      "Epoch: 159..........Loss: 214.02432250976562...........Accuracy: 0.9399999976158142\n",
      "Epoch: 160..........Loss: 58.951622009277344...........Accuracy: 0.9700000286102295\n",
      "Epoch: 161..........Loss: 183.9886474609375...........Accuracy: 0.9300000071525574\n",
      "Epoch: 162..........Loss: 44.761444091796875...........Accuracy: 0.9800000190734863\n",
      "Epoch: 163..........Loss: 167.80722045898438...........Accuracy: 0.9399999976158142\n",
      "Epoch: 164..........Loss: 44.70246887207031...........Accuracy: 0.9700000286102295\n",
      "Epoch: 165..........Loss: 87.90711212158203...........Accuracy: 0.9599999785423279\n",
      "Epoch: 166..........Loss: 128.55052185058594...........Accuracy: 0.9599999785423279\n",
      "Epoch: 167..........Loss: 212.92648315429688...........Accuracy: 0.949999988079071\n",
      "Epoch: 168..........Loss: 191.45816040039062...........Accuracy: 0.9399999976158142\n",
      "Epoch: 169..........Loss: 89.97057342529297...........Accuracy: 0.9700000286102295\n",
      "Epoch: 170..........Loss: 100.39083862304688...........Accuracy: 0.9599999785423279\n",
      "Epoch: 171..........Loss: 321.25701904296875...........Accuracy: 0.8600000143051147\n",
      "Epoch: 172..........Loss: 102.37779235839844...........Accuracy: 0.9399999976158142\n",
      "Epoch: 173..........Loss: 207.05804443359375...........Accuracy: 0.9399999976158142\n",
      "Epoch: 174..........Loss: 83.81875610351562...........Accuracy: 0.9800000190734863\n",
      "Epoch: 175..........Loss: 202.74777221679688...........Accuracy: 0.9300000071525574\n",
      "Epoch: 176..........Loss: 65.89131164550781...........Accuracy: 0.949999988079071\n",
      "Epoch: 177..........Loss: 182.04058837890625...........Accuracy: 0.9399999976158142\n",
      "Epoch: 178..........Loss: 45.43816375732422...........Accuracy: 0.9800000190734863\n",
      "Epoch: 179..........Loss: 43.714881896972656...........Accuracy: 0.9599999785423279\n",
      "Epoch: 180..........Loss: 136.94056701660156...........Accuracy: 0.949999988079071\n",
      "Epoch: 181..........Loss: 94.60228729248047...........Accuracy: 0.9399999976158142\n",
      "Epoch: 182..........Loss: 90.0864028930664...........Accuracy: 0.9800000190734863\n",
      "Epoch: 183..........Loss: 234.21560668945312...........Accuracy: 0.9200000166893005\n",
      "Epoch: 184..........Loss: 179.3047332763672...........Accuracy: 0.949999988079071\n",
      "Epoch: 185..........Loss: 122.73124694824219...........Accuracy: 0.9399999976158142\n",
      "Epoch: 186..........Loss: 243.0420684814453...........Accuracy: 0.8999999761581421\n",
      "Epoch: 187..........Loss: 162.12599182128906...........Accuracy: 0.9399999976158142\n",
      "Epoch: 188..........Loss: 219.01248168945312...........Accuracy: 0.9599999785423279\n",
      "Epoch: 189..........Loss: 225.7710723876953...........Accuracy: 0.9399999976158142\n",
      "Epoch: 190..........Loss: 200.03929138183594...........Accuracy: 0.9300000071525574\n",
      "Epoch: 191..........Loss: 192.4639434814453...........Accuracy: 0.9399999976158142\n",
      "Epoch: 192..........Loss: 54.746517181396484...........Accuracy: 0.9700000286102295\n",
      "Epoch: 193..........Loss: 85.28877258300781...........Accuracy: 0.9399999976158142\n",
      "Epoch: 194..........Loss: 193.72808837890625...........Accuracy: 0.949999988079071\n",
      "Epoch: 195..........Loss: 165.40447998046875...........Accuracy: 0.9200000166893005\n",
      "Epoch: 196..........Loss: 113.23333740234375...........Accuracy: 0.9599999785423279\n",
      "Epoch: 197..........Loss: 138.71014404296875...........Accuracy: 0.9300000071525574\n",
      "Epoch: 198..........Loss: 157.16964721679688...........Accuracy: 0.9599999785423279\n",
      "Epoch: 199..........Loss: 238.42218017578125...........Accuracy: 0.9200000166893005\n",
      "Epoch: 200..........Loss: 294.2911071777344...........Accuracy: 0.9200000166893005\n",
      "Epoch: 201..........Loss: 115.31857299804688...........Accuracy: 0.9300000071525574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 202..........Loss: 163.90162658691406...........Accuracy: 0.9700000286102295\n",
      "Epoch: 203..........Loss: 79.73658752441406...........Accuracy: 0.949999988079071\n",
      "Epoch: 204..........Loss: 140.86135864257812...........Accuracy: 0.9599999785423279\n",
      "Epoch: 205..........Loss: 219.29727172851562...........Accuracy: 0.9200000166893005\n",
      "Epoch: 206..........Loss: 164.86712646484375...........Accuracy: 0.9399999976158142\n",
      "Epoch: 207..........Loss: 144.3225555419922...........Accuracy: 0.949999988079071\n",
      "Epoch: 208..........Loss: 64.81246948242188...........Accuracy: 0.9599999785423279\n",
      "Epoch: 209..........Loss: 145.61814880371094...........Accuracy: 0.9599999785423279\n",
      "Epoch: 210..........Loss: 160.6707305908203...........Accuracy: 0.9200000166893005\n",
      "Epoch: 211..........Loss: 175.8008575439453...........Accuracy: 0.9300000071525574\n",
      "Epoch: 212..........Loss: 53.39053726196289...........Accuracy: 0.9700000286102295\n",
      "Epoch: 213..........Loss: 254.0384521484375...........Accuracy: 0.8799999952316284\n",
      "Epoch: 214..........Loss: 182.9605255126953...........Accuracy: 0.9399999976158142\n",
      "Epoch: 215..........Loss: 212.7996826171875...........Accuracy: 0.9399999976158142\n",
      "Epoch: 216..........Loss: 159.9288330078125...........Accuracy: 0.8899999856948853\n",
      "Epoch: 217..........Loss: 223.36802673339844...........Accuracy: 0.9200000166893005\n",
      "Epoch: 218..........Loss: 126.6737289428711...........Accuracy: 0.9399999976158142\n",
      "Epoch: 219..........Loss: 230.02203369140625...........Accuracy: 0.9300000071525574\n",
      "Epoch: 220..........Loss: 97.32677459716797...........Accuracy: 0.949999988079071\n",
      "Epoch: 221..........Loss: 16.30303192138672...........Accuracy: 0.9800000190734863\n",
      "Epoch: 222..........Loss: 192.2059326171875...........Accuracy: 0.949999988079071\n",
      "Epoch: 223..........Loss: 94.01347351074219...........Accuracy: 0.9399999976158142\n",
      "Epoch: 224..........Loss: 112.21218872070312...........Accuracy: 0.9399999976158142\n",
      "Epoch: 225..........Loss: 137.91200256347656...........Accuracy: 0.9399999976158142\n",
      "Epoch: 226..........Loss: 55.96538162231445...........Accuracy: 0.949999988079071\n",
      "Epoch: 227..........Loss: 85.0665054321289...........Accuracy: 0.949999988079071\n",
      "Epoch: 228..........Loss: 268.66925048828125...........Accuracy: 0.9399999976158142\n",
      "Epoch: 229..........Loss: 218.73379516601562...........Accuracy: 0.8899999856948853\n",
      "Epoch: 230..........Loss: 25.903032302856445...........Accuracy: 0.9700000286102295\n",
      "Epoch: 231..........Loss: 154.79486083984375...........Accuracy: 0.9399999976158142\n",
      "Epoch: 232..........Loss: 71.16382598876953...........Accuracy: 0.949999988079071\n",
      "Epoch: 233..........Loss: 199.15304565429688...........Accuracy: 0.9100000262260437\n",
      "Epoch: 234..........Loss: 164.9610137939453...........Accuracy: 0.9700000286102295\n",
      "Epoch: 235..........Loss: 61.086265563964844...........Accuracy: 0.9599999785423279\n",
      "Epoch: 236..........Loss: 294.8145751953125...........Accuracy: 0.9200000166893005\n",
      "Epoch: 237..........Loss: 108.62734985351562...........Accuracy: 0.9599999785423279\n",
      "Epoch: 238..........Loss: 80.153564453125...........Accuracy: 0.9300000071525574\n",
      "Epoch: 239..........Loss: 68.80561828613281...........Accuracy: 0.9700000286102295\n",
      "Epoch: 240..........Loss: 303.1285400390625...........Accuracy: 0.8899999856948853\n",
      "Epoch: 241..........Loss: 182.27206420898438...........Accuracy: 0.949999988079071\n",
      "Epoch: 242..........Loss: 77.67560577392578...........Accuracy: 0.949999988079071\n",
      "Epoch: 243..........Loss: 149.98146057128906...........Accuracy: 0.9599999785423279\n",
      "Epoch: 244..........Loss: 122.37136840820312...........Accuracy: 0.9300000071525574\n",
      "Epoch: 245..........Loss: 54.31989288330078...........Accuracy: 0.9599999785423279\n",
      "Epoch: 246..........Loss: 238.5410919189453...........Accuracy: 0.9100000262260437\n",
      "Epoch: 247..........Loss: 63.48683547973633...........Accuracy: 0.9300000071525574\n",
      "Epoch: 248..........Loss: 293.3958740234375...........Accuracy: 0.9100000262260437\n",
      "Epoch: 249..........Loss: 417.6282043457031...........Accuracy: 0.9100000262260437\n",
      "Epoch: 250..........Loss: 142.8215789794922...........Accuracy: 0.949999988079071\n",
      "Epoch: 251..........Loss: 172.30899047851562...........Accuracy: 0.9300000071525574\n",
      "Epoch: 252..........Loss: 172.24542236328125...........Accuracy: 0.9300000071525574\n",
      "Epoch: 253..........Loss: 171.55926513671875...........Accuracy: 0.9100000262260437\n",
      "Epoch: 254..........Loss: 157.24655151367188...........Accuracy: 0.9700000286102295\n",
      "Epoch: 255..........Loss: 158.37606811523438...........Accuracy: 0.949999988079071\n",
      "Epoch: 256..........Loss: 119.25447082519531...........Accuracy: 0.9599999785423279\n",
      "Epoch: 257..........Loss: 103.02645874023438...........Accuracy: 0.9399999976158142\n",
      "Epoch: 258..........Loss: 18.42862319946289...........Accuracy: 0.9700000286102295\n",
      "Epoch: 259..........Loss: 203.73690795898438...........Accuracy: 0.9399999976158142\n",
      "Epoch: 260..........Loss: 215.72996520996094...........Accuracy: 0.9700000286102295\n",
      "Epoch: 261..........Loss: 234.59519958496094...........Accuracy: 0.9300000071525574\n",
      "Epoch: 262..........Loss: 11.922929763793945...........Accuracy: 0.9800000190734863\n",
      "Epoch: 263..........Loss: 48.2885856628418...........Accuracy: 0.9599999785423279\n",
      "Epoch: 264..........Loss: 29.207555770874023...........Accuracy: 0.9700000286102295\n",
      "Epoch: 265..........Loss: 142.90487670898438...........Accuracy: 0.9700000286102295\n",
      "Epoch: 266..........Loss: 42.28236389160156...........Accuracy: 0.9700000286102295\n",
      "Epoch: 267..........Loss: 172.2410888671875...........Accuracy: 0.949999988079071\n",
      "Epoch: 268..........Loss: 65.34314727783203...........Accuracy: 0.9399999976158142\n",
      "Epoch: 269..........Loss: 57.83405685424805...........Accuracy: 0.9800000190734863\n",
      "Epoch: 270..........Loss: 296.7486572265625...........Accuracy: 0.9200000166893005\n",
      "Epoch: 271..........Loss: 69.07736206054688...........Accuracy: 0.949999988079071\n",
      "Epoch: 272..........Loss: 170.7098388671875...........Accuracy: 0.9300000071525574\n",
      "Epoch: 273..........Loss: 112.17993927001953...........Accuracy: 0.949999988079071\n",
      "Epoch: 274..........Loss: 89.03523254394531...........Accuracy: 0.949999988079071\n",
      "Epoch: 275..........Loss: 90.022705078125...........Accuracy: 0.9399999976158142\n",
      "Epoch: 276..........Loss: 27.335268020629883...........Accuracy: 0.9599999785423279\n",
      "Epoch: 277..........Loss: 79.64718627929688...........Accuracy: 0.949999988079071\n",
      "Epoch: 278..........Loss: 175.3258056640625...........Accuracy: 0.9300000071525574\n",
      "Epoch: 279..........Loss: 116.22006225585938...........Accuracy: 0.9399999976158142\n",
      "Epoch: 280..........Loss: 88.10558319091797...........Accuracy: 0.9599999785423279\n",
      "Epoch: 281..........Loss: 22.417810440063477...........Accuracy: 0.9900000095367432\n",
      "Epoch: 282..........Loss: 118.5352554321289...........Accuracy: 0.9399999976158142\n",
      "Epoch: 283..........Loss: 14.155603408813477...........Accuracy: 0.9800000190734863\n",
      "Epoch: 284..........Loss: 22.047439575195312...........Accuracy: 0.9700000286102295\n",
      "Epoch: 285..........Loss: 49.30644607543945...........Accuracy: 0.949999988079071\n",
      "Epoch: 286..........Loss: 80.1913833618164...........Accuracy: 0.9399999976158142\n",
      "Epoch: 287..........Loss: 170.41851806640625...........Accuracy: 0.9599999785423279\n",
      "Epoch: 288..........Loss: 226.22779846191406...........Accuracy: 0.9300000071525574\n",
      "Epoch: 289..........Loss: 83.56291198730469...........Accuracy: 0.9399999976158142\n",
      "Epoch: 290..........Loss: 43.82732391357422...........Accuracy: 0.9700000286102295\n",
      "Epoch: 291..........Loss: 255.7200164794922...........Accuracy: 0.949999988079071\n",
      "Epoch: 292..........Loss: 76.84757995605469...........Accuracy: 0.949999988079071\n",
      "Epoch: 293..........Loss: 63.90785217285156...........Accuracy: 0.9599999785423279\n",
      "Epoch: 294..........Loss: 137.75579833984375...........Accuracy: 0.9399999976158142\n",
      "Epoch: 295..........Loss: 148.97621154785156...........Accuracy: 0.9100000262260437\n",
      "Epoch: 296..........Loss: 25.149389266967773...........Accuracy: 0.9900000095367432\n",
      "Epoch: 297..........Loss: 142.5711669921875...........Accuracy: 0.949999988079071\n",
      "Epoch: 298..........Loss: 182.45822143554688...........Accuracy: 0.9200000166893005\n",
      "Epoch: 299..........Loss: 55.928077697753906...........Accuracy: 0.9700000286102295\n",
      "Epoch: 300..........Loss: 16.104652404785156...........Accuracy: 0.9800000190734863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 301..........Loss: 64.6446762084961...........Accuracy: 0.9599999785423279\n",
      "Epoch: 302..........Loss: 177.2081298828125...........Accuracy: 0.9399999976158142\n",
      "Epoch: 303..........Loss: 37.822540283203125...........Accuracy: 0.9700000286102295\n",
      "Epoch: 304..........Loss: 35.244510650634766...........Accuracy: 0.9900000095367432\n",
      "Epoch: 305..........Loss: 144.5201416015625...........Accuracy: 0.9599999785423279\n",
      "Epoch: 306..........Loss: 258.9249267578125...........Accuracy: 0.8899999856948853\n",
      "Epoch: 307..........Loss: 90.70838928222656...........Accuracy: 0.9900000095367432\n",
      "Epoch: 308..........Loss: 161.37686157226562...........Accuracy: 0.9399999976158142\n",
      "Epoch: 309..........Loss: 100.56146240234375...........Accuracy: 0.9599999785423279\n",
      "Epoch: 310..........Loss: 53.771183013916016...........Accuracy: 0.9800000190734863\n",
      "Epoch: 311..........Loss: 88.99654388427734...........Accuracy: 0.9300000071525574\n",
      "Epoch: 312..........Loss: 45.32219696044922...........Accuracy: 0.9800000190734863\n",
      "Epoch: 313..........Loss: 57.87287139892578...........Accuracy: 0.949999988079071\n",
      "Epoch: 314..........Loss: 210.0978546142578...........Accuracy: 0.9399999976158142\n",
      "Epoch: 315..........Loss: 56.605064392089844...........Accuracy: 0.9700000286102295\n",
      "Epoch: 316..........Loss: 138.15867614746094...........Accuracy: 0.9599999785423279\n",
      "Epoch: 317..........Loss: 73.73267364501953...........Accuracy: 0.949999988079071\n",
      "Epoch: 318..........Loss: 96.84814453125...........Accuracy: 0.949999988079071\n",
      "Epoch: 319..........Loss: 6.168254375457764...........Accuracy: 0.9900000095367432\n",
      "Epoch: 320..........Loss: 114.70083618164062...........Accuracy: 0.9300000071525574\n",
      "Epoch: 321..........Loss: 65.8203125...........Accuracy: 0.9700000286102295\n",
      "Epoch: 322..........Loss: 95.625732421875...........Accuracy: 0.949999988079071\n",
      "Epoch: 323..........Loss: 49.39018630981445...........Accuracy: 0.9300000071525574\n",
      "Epoch: 324..........Loss: 132.38665771484375...........Accuracy: 0.949999988079071\n",
      "Epoch: 325..........Loss: 105.7761001586914...........Accuracy: 0.949999988079071\n",
      "Epoch: 326..........Loss: 143.65115356445312...........Accuracy: 0.9599999785423279\n",
      "Epoch: 327..........Loss: 139.2841796875...........Accuracy: 0.9700000286102295\n",
      "Epoch: 328..........Loss: 131.3917999267578...........Accuracy: 0.9700000286102295\n",
      "Epoch: 329..........Loss: 19.6212215423584...........Accuracy: 0.9900000095367432\n",
      "Epoch: 330..........Loss: 55.044647216796875...........Accuracy: 0.9700000286102295\n",
      "Epoch: 331..........Loss: 173.67848205566406...........Accuracy: 0.9100000262260437\n",
      "Epoch: 332..........Loss: 111.3690414428711...........Accuracy: 0.949999988079071\n",
      "Epoch: 333..........Loss: 107.58184814453125...........Accuracy: 0.9599999785423279\n",
      "Epoch: 334..........Loss: 60.850135803222656...........Accuracy: 0.9599999785423279\n",
      "Epoch: 335..........Loss: 239.1168212890625...........Accuracy: 0.949999988079071\n",
      "Epoch: 336..........Loss: 170.37355041503906...........Accuracy: 0.9300000071525574\n",
      "Epoch: 337..........Loss: 42.26850891113281...........Accuracy: 0.9399999976158142\n",
      "Epoch: 338..........Loss: 215.53273010253906...........Accuracy: 0.9200000166893005\n",
      "Epoch: 339..........Loss: 129.93423461914062...........Accuracy: 0.9200000166893005\n",
      "Epoch: 340..........Loss: 125.75694274902344...........Accuracy: 0.9599999785423279\n",
      "Epoch: 341..........Loss: 142.14608764648438...........Accuracy: 0.949999988079071\n",
      "Epoch: 342..........Loss: 124.88894653320312...........Accuracy: 0.9599999785423279\n",
      "Epoch: 343..........Loss: 100.35517883300781...........Accuracy: 0.9300000071525574\n",
      "Epoch: 344..........Loss: 98.10086059570312...........Accuracy: 0.9399999976158142\n",
      "Epoch: 345..........Loss: 90.79007720947266...........Accuracy: 0.9399999976158142\n",
      "Epoch: 346..........Loss: 142.99456787109375...........Accuracy: 0.949999988079071\n",
      "Epoch: 347..........Loss: 112.59229278564453...........Accuracy: 0.9599999785423279\n",
      "Epoch: 348..........Loss: 104.61090087890625...........Accuracy: 0.9399999976158142\n",
      "Epoch: 349..........Loss: 1.2794408798217773...........Accuracy: 0.9900000095367432\n",
      "Epoch: 350..........Loss: 43.557960510253906...........Accuracy: 0.949999988079071\n",
      "Epoch: 351..........Loss: 52.46923828125...........Accuracy: 0.9599999785423279\n",
      "Epoch: 352..........Loss: 216.52374267578125...........Accuracy: 0.9399999976158142\n",
      "Epoch: 353..........Loss: 87.10603332519531...........Accuracy: 0.949999988079071\n",
      "Epoch: 354..........Loss: 152.6191864013672...........Accuracy: 0.9300000071525574\n",
      "Epoch: 355..........Loss: 49.933563232421875...........Accuracy: 0.9800000190734863\n",
      "Epoch: 356..........Loss: 136.45828247070312...........Accuracy: 0.9300000071525574\n",
      "Epoch: 357..........Loss: 153.59075927734375...........Accuracy: 0.9399999976158142\n",
      "Epoch: 358..........Loss: 211.25015258789062...........Accuracy: 0.9399999976158142\n",
      "Epoch: 359..........Loss: 97.74665832519531...........Accuracy: 0.9599999785423279\n",
      "Epoch: 360..........Loss: 111.51237487792969...........Accuracy: 0.9700000286102295\n",
      "Epoch: 361..........Loss: 142.29281616210938...........Accuracy: 0.9599999785423279\n",
      "Epoch: 362..........Loss: 19.504261016845703...........Accuracy: 0.9800000190734863\n",
      "Epoch: 363..........Loss: 110.83622741699219...........Accuracy: 0.9599999785423279\n",
      "Epoch: 364..........Loss: 57.012489318847656...........Accuracy: 0.9800000190734863\n",
      "Epoch: 365..........Loss: 43.2145881652832...........Accuracy: 0.9700000286102295\n",
      "Epoch: 366..........Loss: 146.04066467285156...........Accuracy: 0.9599999785423279\n",
      "Epoch: 367..........Loss: 174.2899169921875...........Accuracy: 0.9300000071525574\n",
      "Epoch: 368..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 369..........Loss: 248.30697631835938...........Accuracy: 0.8899999856948853\n",
      "Epoch: 370..........Loss: 134.08761596679688...........Accuracy: 0.9700000286102295\n",
      "Epoch: 371..........Loss: 259.3723449707031...........Accuracy: 0.9300000071525574\n",
      "Epoch: 372..........Loss: 62.95475769042969...........Accuracy: 0.9599999785423279\n",
      "Epoch: 373..........Loss: 122.39041137695312...........Accuracy: 0.9100000262260437\n",
      "Epoch: 374..........Loss: 161.79409790039062...........Accuracy: 0.9399999976158142\n",
      "Epoch: 375..........Loss: 187.47842407226562...........Accuracy: 0.9300000071525574\n",
      "Epoch: 376..........Loss: 106.43795013427734...........Accuracy: 0.949999988079071\n",
      "Epoch: 377..........Loss: 40.22651290893555...........Accuracy: 0.9700000286102295\n",
      "Epoch: 378..........Loss: 109.7345962524414...........Accuracy: 0.949999988079071\n",
      "Epoch: 379..........Loss: 209.16000366210938...........Accuracy: 0.9399999976158142\n",
      "Epoch: 380..........Loss: 45.870941162109375...........Accuracy: 0.9700000286102295\n",
      "Epoch: 381..........Loss: 122.1679458618164...........Accuracy: 0.949999988079071\n",
      "Epoch: 382..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 383..........Loss: 60.79164505004883...........Accuracy: 0.9700000286102295\n",
      "Epoch: 384..........Loss: 14.97079086303711...........Accuracy: 0.9900000095367432\n",
      "Epoch: 385..........Loss: 49.174190521240234...........Accuracy: 0.9800000190734863\n",
      "Epoch: 386..........Loss: 73.6628646850586...........Accuracy: 0.9399999976158142\n",
      "Epoch: 387..........Loss: 69.85282135009766...........Accuracy: 0.9599999785423279\n",
      "Epoch: 388..........Loss: 36.7340087890625...........Accuracy: 0.9700000286102295\n",
      "Epoch: 389..........Loss: 16.530359268188477...........Accuracy: 0.9800000190734863\n",
      "Epoch: 390..........Loss: 149.97694396972656...........Accuracy: 0.9300000071525574\n",
      "Epoch: 391..........Loss: 198.2798309326172...........Accuracy: 0.9200000166893005\n",
      "Epoch: 392..........Loss: 12.894597053527832...........Accuracy: 0.9800000190734863\n",
      "Epoch: 393..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 394..........Loss: 7.478232383728027...........Accuracy: 0.9700000286102295\n",
      "Epoch: 395..........Loss: 28.51162338256836...........Accuracy: 0.949999988079071\n",
      "Epoch: 396..........Loss: 411.984619140625...........Accuracy: 0.8799999952316284\n",
      "Epoch: 397..........Loss: 35.201534271240234...........Accuracy: 0.9700000286102295\n",
      "Epoch: 398..........Loss: 7.249111175537109...........Accuracy: 0.9800000190734863\n",
      "Epoch: 399..........Loss: 96.09972381591797...........Accuracy: 0.9399999976158142\n",
      "Epoch: 400..........Loss: 70.0207748413086...........Accuracy: 0.9700000286102295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 401..........Loss: 25.4384708404541...........Accuracy: 0.9800000190734863\n",
      "Epoch: 402..........Loss: 5.82760763168335...........Accuracy: 0.9900000095367432\n",
      "Epoch: 403..........Loss: 91.67986297607422...........Accuracy: 0.9700000286102295\n",
      "Epoch: 404..........Loss: 62.374267578125...........Accuracy: 0.949999988079071\n",
      "Epoch: 405..........Loss: 70.44367980957031...........Accuracy: 0.9599999785423279\n",
      "Epoch: 406..........Loss: 20.01024627685547...........Accuracy: 0.9800000190734863\n",
      "Epoch: 407..........Loss: 55.57332992553711...........Accuracy: 0.9599999785423279\n",
      "Epoch: 408..........Loss: 30.952611923217773...........Accuracy: 0.9700000286102295\n",
      "Epoch: 409..........Loss: 98.04488372802734...........Accuracy: 0.949999988079071\n",
      "Epoch: 410..........Loss: 191.7755126953125...........Accuracy: 0.9200000166893005\n",
      "Epoch: 411..........Loss: 65.75163269042969...........Accuracy: 0.949999988079071\n",
      "Epoch: 412..........Loss: 100.10822296142578...........Accuracy: 0.9599999785423279\n",
      "Epoch: 413..........Loss: 29.931591033935547...........Accuracy: 0.9599999785423279\n",
      "Epoch: 414..........Loss: 79.11986541748047...........Accuracy: 0.9399999976158142\n",
      "Epoch: 415..........Loss: 84.4208984375...........Accuracy: 0.9599999785423279\n",
      "Epoch: 416..........Loss: 82.05626678466797...........Accuracy: 0.9800000190734863\n",
      "Epoch: 417..........Loss: 40.807106018066406...........Accuracy: 0.9700000286102295\n",
      "Epoch: 418..........Loss: 224.83367919921875...........Accuracy: 0.9399999976158142\n",
      "Epoch: 419..........Loss: 166.3371124267578...........Accuracy: 0.9599999785423279\n",
      "Epoch: 420..........Loss: 44.46873092651367...........Accuracy: 0.9800000190734863\n",
      "Epoch: 421..........Loss: 170.90554809570312...........Accuracy: 0.9399999976158142\n",
      "Epoch: 422..........Loss: 38.72968673706055...........Accuracy: 0.9599999785423279\n",
      "Epoch: 423..........Loss: 118.9205093383789...........Accuracy: 0.9300000071525574\n",
      "Epoch: 424..........Loss: 84.78868103027344...........Accuracy: 0.949999988079071\n",
      "Epoch: 425..........Loss: 116.9902572631836...........Accuracy: 0.9200000166893005\n",
      "Epoch: 426..........Loss: 75.68622589111328...........Accuracy: 0.9300000071525574\n",
      "Epoch: 427..........Loss: 67.57547760009766...........Accuracy: 0.949999988079071\n",
      "Epoch: 428..........Loss: 114.59930419921875...........Accuracy: 0.9700000286102295\n",
      "Epoch: 429..........Loss: 21.360010147094727...........Accuracy: 0.9900000095367432\n",
      "Epoch: 430..........Loss: 76.94807434082031...........Accuracy: 0.9900000095367432\n",
      "Epoch: 431..........Loss: 52.38750076293945...........Accuracy: 0.9700000286102295\n",
      "Epoch: 432..........Loss: 69.75736999511719...........Accuracy: 0.9599999785423279\n",
      "Epoch: 433..........Loss: 21.846237182617188...........Accuracy: 0.9800000190734863\n",
      "Epoch: 434..........Loss: 58.211734771728516...........Accuracy: 0.949999988079071\n",
      "Epoch: 435..........Loss: 94.5543441772461...........Accuracy: 0.949999988079071\n",
      "Epoch: 436..........Loss: 68.0718765258789...........Accuracy: 0.9599999785423279\n",
      "Epoch: 437..........Loss: 134.02601623535156...........Accuracy: 0.949999988079071\n",
      "Epoch: 438..........Loss: 132.10162353515625...........Accuracy: 0.9399999976158142\n",
      "Epoch: 439..........Loss: 179.40089416503906...........Accuracy: 0.949999988079071\n",
      "Epoch: 440..........Loss: 57.554718017578125...........Accuracy: 0.9599999785423279\n",
      "Epoch: 441..........Loss: 27.968290328979492...........Accuracy: 0.9599999785423279\n",
      "Epoch: 442..........Loss: 43.910152435302734...........Accuracy: 0.9599999785423279\n",
      "Epoch: 443..........Loss: 42.36321258544922...........Accuracy: 0.9800000190734863\n",
      "Epoch: 444..........Loss: 29.215904235839844...........Accuracy: 0.9700000286102295\n",
      "Epoch: 445..........Loss: 47.018089294433594...........Accuracy: 0.9700000286102295\n",
      "Epoch: 446..........Loss: 62.8221435546875...........Accuracy: 0.9599999785423279\n",
      "Epoch: 447..........Loss: 101.18046569824219...........Accuracy: 0.9399999976158142\n",
      "Epoch: 448..........Loss: 85.75424194335938...........Accuracy: 0.9200000166893005\n",
      "Epoch: 449..........Loss: 82.73475646972656...........Accuracy: 0.9599999785423279\n",
      "Epoch: 450..........Loss: 131.41217041015625...........Accuracy: 0.9599999785423279\n",
      "Epoch: 451..........Loss: 54.89781188964844...........Accuracy: 0.9700000286102295\n",
      "Epoch: 452..........Loss: 32.411685943603516...........Accuracy: 0.9700000286102295\n",
      "Epoch: 453..........Loss: 45.466190338134766...........Accuracy: 0.9399999976158142\n",
      "Epoch: 454..........Loss: 43.33251953125...........Accuracy: 0.9700000286102295\n",
      "Epoch: 455..........Loss: 82.0805892944336...........Accuracy: 0.949999988079071\n",
      "Epoch: 456..........Loss: 37.80693054199219...........Accuracy: 0.9599999785423279\n",
      "Epoch: 457..........Loss: 63.84209442138672...........Accuracy: 0.9700000286102295\n",
      "Epoch: 458..........Loss: 73.06029510498047...........Accuracy: 0.9700000286102295\n",
      "Epoch: 459..........Loss: 123.4873046875...........Accuracy: 0.9399999976158142\n",
      "Epoch: 460..........Loss: 72.81315612792969...........Accuracy: 0.9300000071525574\n",
      "Epoch: 461..........Loss: 64.5034408569336...........Accuracy: 0.9599999785423279\n",
      "Epoch: 462..........Loss: 107.50712585449219...........Accuracy: 0.9599999785423279\n",
      "Epoch: 463..........Loss: 132.75906372070312...........Accuracy: 0.949999988079071\n",
      "Epoch: 464..........Loss: 88.85954284667969...........Accuracy: 0.949999988079071\n",
      "Epoch: 465..........Loss: 101.78361511230469...........Accuracy: 0.949999988079071\n",
      "Epoch: 466..........Loss: 70.97216033935547...........Accuracy: 0.949999988079071\n",
      "Epoch: 467..........Loss: 176.48419189453125...........Accuracy: 0.9200000166893005\n",
      "Epoch: 468..........Loss: 51.315486907958984...........Accuracy: 0.9599999785423279\n",
      "Epoch: 469..........Loss: 6.743322849273682...........Accuracy: 0.9800000190734863\n",
      "Epoch: 470..........Loss: 4.126450061798096...........Accuracy: 0.9900000095367432\n",
      "Epoch: 471..........Loss: 21.34783935546875...........Accuracy: 0.9800000190734863\n",
      "Epoch: 472..........Loss: 96.65087127685547...........Accuracy: 0.9700000286102295\n",
      "Epoch: 473..........Loss: 111.46501922607422...........Accuracy: 0.9599999785423279\n",
      "Epoch: 474..........Loss: 174.1709442138672...........Accuracy: 0.9599999785423279\n",
      "Epoch: 475..........Loss: 39.05613327026367...........Accuracy: 0.9800000190734863\n",
      "Epoch: 476..........Loss: 160.06704711914062...........Accuracy: 0.9100000262260437\n",
      "Epoch: 477..........Loss: 140.1935577392578...........Accuracy: 0.9300000071525574\n",
      "Epoch: 478..........Loss: 53.03792953491211...........Accuracy: 0.949999988079071\n",
      "Epoch: 479..........Loss: 57.069435119628906...........Accuracy: 0.9700000286102295\n",
      "Epoch: 480..........Loss: 29.113544464111328...........Accuracy: 0.9599999785423279\n",
      "Epoch: 481..........Loss: 124.5809555053711...........Accuracy: 0.9700000286102295\n",
      "Epoch: 482..........Loss: 57.449588775634766...........Accuracy: 0.949999988079071\n",
      "Epoch: 483..........Loss: 52.7050895690918...........Accuracy: 0.949999988079071\n",
      "Epoch: 484..........Loss: 30.004684448242188...........Accuracy: 0.9700000286102295\n",
      "Epoch: 485..........Loss: 59.77910232543945...........Accuracy: 0.9700000286102295\n",
      "Epoch: 486..........Loss: 29.048507690429688...........Accuracy: 0.9599999785423279\n",
      "Epoch: 487..........Loss: 28.209810256958008...........Accuracy: 0.9800000190734863\n",
      "Epoch: 488..........Loss: 43.68809509277344...........Accuracy: 0.9700000286102295\n",
      "Epoch: 489..........Loss: 21.06783676147461...........Accuracy: 0.9800000190734863\n",
      "Epoch: 490..........Loss: 132.7593994140625...........Accuracy: 0.9700000286102295\n",
      "Epoch: 491..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 492..........Loss: 173.09193420410156...........Accuracy: 0.949999988079071\n",
      "Epoch: 493..........Loss: 221.1706085205078...........Accuracy: 0.9100000262260437\n",
      "Epoch: 494..........Loss: 58.3768424987793...........Accuracy: 0.9599999785423279\n",
      "Epoch: 495..........Loss: 74.10979461669922...........Accuracy: 0.9700000286102295\n",
      "Epoch: 496..........Loss: 45.664207458496094...........Accuracy: 0.9800000190734863\n",
      "Epoch: 497..........Loss: 44.728946685791016...........Accuracy: 0.9800000190734863\n",
      "Epoch: 498..........Loss: 215.5640411376953...........Accuracy: 0.9100000262260437\n",
      "Epoch: 499..........Loss: 86.6661148071289...........Accuracy: 0.9599999785423279\n",
      "Epoch: 500..........Loss: 73.90032958984375...........Accuracy: 0.9200000166893005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 501..........Loss: 34.11716842651367...........Accuracy: 0.9700000286102295\n",
      "Epoch: 502..........Loss: 30.80113983154297...........Accuracy: 0.9599999785423279\n",
      "Epoch: 503..........Loss: 61.435001373291016...........Accuracy: 0.9599999785423279\n",
      "Epoch: 504..........Loss: 26.464370727539062...........Accuracy: 0.9700000286102295\n",
      "Epoch: 505..........Loss: 92.25216674804688...........Accuracy: 0.9700000286102295\n",
      "Epoch: 506..........Loss: 131.24049377441406...........Accuracy: 0.949999988079071\n",
      "Epoch: 507..........Loss: 7.59014892578125...........Accuracy: 0.9700000286102295\n",
      "Epoch: 508..........Loss: 27.32125473022461...........Accuracy: 0.9800000190734863\n",
      "Epoch: 509..........Loss: 62.996280670166016...........Accuracy: 0.9900000095367432\n",
      "Epoch: 510..........Loss: 60.779727935791016...........Accuracy: 0.9399999976158142\n",
      "Epoch: 511..........Loss: 40.86491775512695...........Accuracy: 0.9599999785423279\n",
      "Epoch: 512..........Loss: 151.9796142578125...........Accuracy: 0.9399999976158142\n",
      "Epoch: 513..........Loss: 55.21324157714844...........Accuracy: 0.9800000190734863\n",
      "Epoch: 514..........Loss: 186.06834411621094...........Accuracy: 0.9200000166893005\n",
      "Epoch: 515..........Loss: 31.13555145263672...........Accuracy: 0.9700000286102295\n",
      "Epoch: 516..........Loss: 87.35211181640625...........Accuracy: 0.9300000071525574\n",
      "Epoch: 517..........Loss: 43.004024505615234...........Accuracy: 0.9700000286102295\n",
      "Epoch: 518..........Loss: 89.29029083251953...........Accuracy: 0.9399999976158142\n",
      "Epoch: 519..........Loss: 78.81378936767578...........Accuracy: 0.949999988079071\n",
      "Epoch: 520..........Loss: 67.2972183227539...........Accuracy: 0.949999988079071\n",
      "Epoch: 521..........Loss: 3.0445165634155273...........Accuracy: 0.9900000095367432\n",
      "Epoch: 522..........Loss: 247.0721435546875...........Accuracy: 0.9200000166893005\n",
      "Epoch: 523..........Loss: 93.55400085449219...........Accuracy: 0.9599999785423279\n",
      "Epoch: 524..........Loss: 91.37657165527344...........Accuracy: 0.9200000166893005\n",
      "Epoch: 525..........Loss: 62.48297882080078...........Accuracy: 0.9800000190734863\n",
      "Epoch: 526..........Loss: 9.059423446655273...........Accuracy: 0.9900000095367432\n",
      "Epoch: 527..........Loss: 55.66179656982422...........Accuracy: 0.9800000190734863\n",
      "Epoch: 528..........Loss: 25.2612361907959...........Accuracy: 0.9900000095367432\n",
      "Epoch: 529..........Loss: 9.59988021850586...........Accuracy: 0.9900000095367432\n",
      "Epoch: 530..........Loss: 50.2962760925293...........Accuracy: 0.9599999785423279\n",
      "Epoch: 531..........Loss: 119.96347045898438...........Accuracy: 0.9300000071525574\n",
      "Epoch: 532..........Loss: 66.1467056274414...........Accuracy: 0.9700000286102295\n",
      "Epoch: 533..........Loss: 33.321720123291016...........Accuracy: 0.9599999785423279\n",
      "Epoch: 534..........Loss: 19.81375503540039...........Accuracy: 0.9700000286102295\n",
      "Epoch: 535..........Loss: 25.410972595214844...........Accuracy: 0.9700000286102295\n",
      "Epoch: 536..........Loss: 48.05076217651367...........Accuracy: 0.949999988079071\n",
      "Epoch: 537..........Loss: 189.5157012939453...........Accuracy: 0.9300000071525574\n",
      "Epoch: 538..........Loss: 92.8076171875...........Accuracy: 0.949999988079071\n",
      "Epoch: 539..........Loss: 16.92062759399414...........Accuracy: 0.9800000190734863\n",
      "Epoch: 540..........Loss: 59.740089416503906...........Accuracy: 0.949999988079071\n",
      "Epoch: 541..........Loss: 65.34637451171875...........Accuracy: 0.9700000286102295\n",
      "Epoch: 542..........Loss: 112.01809692382812...........Accuracy: 0.9399999976158142\n",
      "Epoch: 543..........Loss: 137.87265014648438...........Accuracy: 0.9399999976158142\n",
      "Epoch: 544..........Loss: 91.60636901855469...........Accuracy: 0.9599999785423279\n",
      "Epoch: 545..........Loss: 91.08477783203125...........Accuracy: 0.9599999785423279\n",
      "Epoch: 546..........Loss: 94.7583999633789...........Accuracy: 0.949999988079071\n",
      "Epoch: 547..........Loss: 52.6596565246582...........Accuracy: 0.9800000190734863\n",
      "Epoch: 548..........Loss: 17.480825424194336...........Accuracy: 0.9900000095367432\n",
      "Epoch: 549..........Loss: 70.8750991821289...........Accuracy: 0.9599999785423279\n",
      "Epoch: 550..........Loss: 2.467028856277466...........Accuracy: 0.9800000190734863\n",
      "Epoch: 551..........Loss: 2.027958869934082...........Accuracy: 0.9900000095367432\n",
      "Epoch: 552..........Loss: 57.932979583740234...........Accuracy: 0.9700000286102295\n",
      "Epoch: 553..........Loss: 25.613481521606445...........Accuracy: 0.9700000286102295\n",
      "Epoch: 554..........Loss: 85.6412124633789...........Accuracy: 0.9800000190734863\n",
      "Epoch: 555..........Loss: 76.78073120117188...........Accuracy: 0.9700000286102295\n",
      "Epoch: 556..........Loss: 28.644067764282227...........Accuracy: 0.9599999785423279\n",
      "Epoch: 557..........Loss: 107.22237396240234...........Accuracy: 0.9700000286102295\n",
      "Epoch: 558..........Loss: 10.266518592834473...........Accuracy: 0.9800000190734863\n",
      "Epoch: 559..........Loss: 23.127729415893555...........Accuracy: 0.9700000286102295\n",
      "Epoch: 560..........Loss: 64.79846954345703...........Accuracy: 0.9800000190734863\n",
      "Epoch: 561..........Loss: 33.66709899902344...........Accuracy: 0.949999988079071\n",
      "Epoch: 562..........Loss: 33.788421630859375...........Accuracy: 0.9599999785423279\n",
      "Epoch: 563..........Loss: 49.870338439941406...........Accuracy: 0.9700000286102295\n",
      "Epoch: 564..........Loss: 57.58517074584961...........Accuracy: 0.9599999785423279\n",
      "Epoch: 565..........Loss: 29.778907775878906...........Accuracy: 0.9800000190734863\n",
      "Epoch: 566..........Loss: 78.45015716552734...........Accuracy: 0.9599999785423279\n",
      "Epoch: 567..........Loss: 7.45907735824585...........Accuracy: 0.9900000095367432\n",
      "Epoch: 568..........Loss: 80.2049789428711...........Accuracy: 0.949999988079071\n",
      "Epoch: 569..........Loss: 49.6157341003418...........Accuracy: 0.9700000286102295\n",
      "Epoch: 570..........Loss: 66.31238555908203...........Accuracy: 0.9700000286102295\n",
      "Epoch: 571..........Loss: 59.634944915771484...........Accuracy: 0.9599999785423279\n",
      "Epoch: 572..........Loss: 3.6385180950164795...........Accuracy: 0.9900000095367432\n",
      "Epoch: 573..........Loss: 16.933982849121094...........Accuracy: 0.9800000190734863\n",
      "Epoch: 574..........Loss: 51.950382232666016...........Accuracy: 0.949999988079071\n",
      "Epoch: 575..........Loss: 18.64510726928711...........Accuracy: 0.9900000095367432\n",
      "Epoch: 576..........Loss: 78.16313171386719...........Accuracy: 0.949999988079071\n",
      "Epoch: 577..........Loss: 41.2414665222168...........Accuracy: 0.949999988079071\n",
      "Epoch: 578..........Loss: 8.085619926452637...........Accuracy: 0.9900000095367432\n",
      "Epoch: 579..........Loss: 69.27018737792969...........Accuracy: 0.9700000286102295\n",
      "Epoch: 580..........Loss: 10.145903587341309...........Accuracy: 0.9800000190734863\n",
      "Epoch: 581..........Loss: 8.478066444396973...........Accuracy: 0.9900000095367432\n",
      "Epoch: 582..........Loss: 14.948984146118164...........Accuracy: 0.9900000095367432\n",
      "Epoch: 583..........Loss: 35.16064453125...........Accuracy: 0.9700000286102295\n",
      "Epoch: 584..........Loss: 41.28104019165039...........Accuracy: 0.9900000095367432\n",
      "Epoch: 585..........Loss: 69.96090698242188...........Accuracy: 0.9599999785423279\n",
      "Epoch: 586..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 587..........Loss: 114.05783081054688...........Accuracy: 0.9300000071525574\n",
      "Epoch: 588..........Loss: 31.488874435424805...........Accuracy: 0.949999988079071\n",
      "Epoch: 589..........Loss: 35.331180572509766...........Accuracy: 0.9900000095367432\n",
      "Epoch: 590..........Loss: 0.0763622522354126...........Accuracy: 0.9900000095367432\n",
      "Epoch: 591..........Loss: 25.41693115234375...........Accuracy: 0.9800000190734863\n",
      "Epoch: 592..........Loss: 19.449508666992188...........Accuracy: 0.9900000095367432\n",
      "Epoch: 593..........Loss: 54.053855895996094...........Accuracy: 0.9599999785423279\n",
      "Epoch: 594..........Loss: 18.205080032348633...........Accuracy: 0.9800000190734863\n",
      "Epoch: 595..........Loss: 29.281248092651367...........Accuracy: 0.9700000286102295\n",
      "Epoch: 596..........Loss: 99.7623062133789...........Accuracy: 0.9800000190734863\n",
      "Epoch: 597..........Loss: 138.84178161621094...........Accuracy: 0.9300000071525574\n",
      "Epoch: 598..........Loss: 20.118335723876953...........Accuracy: 0.9700000286102295\n",
      "Epoch: 599..........Loss: 33.218177795410156...........Accuracy: 0.9800000190734863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 600..........Loss: 43.345977783203125...........Accuracy: 0.9599999785423279\n",
      "Epoch: 601..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 602..........Loss: 133.10452270507812...........Accuracy: 0.9700000286102295\n",
      "Epoch: 603..........Loss: 40.86354446411133...........Accuracy: 0.9599999785423279\n",
      "Epoch: 604..........Loss: 25.56182098388672...........Accuracy: 0.9800000190734863\n",
      "Epoch: 605..........Loss: 28.480810165405273...........Accuracy: 0.9800000190734863\n",
      "Epoch: 606..........Loss: 62.23549270629883...........Accuracy: 0.9700000286102295\n",
      "Epoch: 607..........Loss: 3.154355525970459...........Accuracy: 0.9900000095367432\n",
      "Epoch: 608..........Loss: 150.05274963378906...........Accuracy: 0.949999988079071\n",
      "Epoch: 609..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 610..........Loss: 30.910688400268555...........Accuracy: 0.9800000190734863\n",
      "Epoch: 611..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 612..........Loss: 26.576322555541992...........Accuracy: 0.9800000190734863\n",
      "Epoch: 613..........Loss: 29.198192596435547...........Accuracy: 0.9900000095367432\n",
      "Epoch: 614..........Loss: 74.49815368652344...........Accuracy: 0.9599999785423279\n",
      "Epoch: 615..........Loss: 4.647758960723877...........Accuracy: 0.9900000095367432\n",
      "Epoch: 616..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 617..........Loss: 35.23278045654297...........Accuracy: 0.9900000095367432\n",
      "Epoch: 618..........Loss: 45.288787841796875...........Accuracy: 0.9700000286102295\n",
      "Epoch: 619..........Loss: 63.04380798339844...........Accuracy: 0.9800000190734863\n",
      "Epoch: 620..........Loss: 86.48164367675781...........Accuracy: 0.9599999785423279\n",
      "Epoch: 621..........Loss: 88.33757781982422...........Accuracy: 0.9599999785423279\n",
      "Epoch: 622..........Loss: 20.9128360748291...........Accuracy: 0.9900000095367432\n",
      "Epoch: 623..........Loss: 2.3824169635772705...........Accuracy: 0.9900000095367432\n",
      "Epoch: 624..........Loss: 56.947017669677734...........Accuracy: 0.9700000286102295\n",
      "Epoch: 625..........Loss: 31.78520965576172...........Accuracy: 0.9800000190734863\n",
      "Epoch: 626..........Loss: 35.85902786254883...........Accuracy: 0.9800000190734863\n",
      "Epoch: 627..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 628..........Loss: 30.573083877563477...........Accuracy: 0.9800000190734863\n",
      "Epoch: 629..........Loss: 98.14798736572266...........Accuracy: 0.949999988079071\n",
      "Epoch: 630..........Loss: 6.539038181304932...........Accuracy: 0.9800000190734863\n",
      "Epoch: 631..........Loss: 16.114795684814453...........Accuracy: 0.9900000095367432\n",
      "Epoch: 632..........Loss: 3.797055721282959...........Accuracy: 0.9900000095367432\n",
      "Epoch: 633..........Loss: 30.586620330810547...........Accuracy: 0.9700000286102295\n",
      "Epoch: 634..........Loss: 63.57798767089844...........Accuracy: 0.9800000190734863\n",
      "Epoch: 635..........Loss: 102.03689575195312...........Accuracy: 0.949999988079071\n",
      "Epoch: 636..........Loss: 23.18694305419922...........Accuracy: 0.9900000095367432\n",
      "Epoch: 637..........Loss: 28.290386199951172...........Accuracy: 0.9599999785423279\n",
      "Epoch: 638..........Loss: 5.860195159912109...........Accuracy: 0.9800000190734863\n",
      "Epoch: 639..........Loss: 66.73991394042969...........Accuracy: 0.9300000071525574\n",
      "Epoch: 640..........Loss: 102.60237121582031...........Accuracy: 0.949999988079071\n",
      "Epoch: 641..........Loss: 17.415729522705078...........Accuracy: 0.9800000190734863\n",
      "Epoch: 642..........Loss: 13.66946792602539...........Accuracy: 0.9900000095367432\n",
      "Epoch: 643..........Loss: 36.93455505371094...........Accuracy: 0.9800000190734863\n",
      "Epoch: 644..........Loss: 54.653045654296875...........Accuracy: 0.9700000286102295\n",
      "Epoch: 645..........Loss: 30.29007339477539...........Accuracy: 0.9599999785423279\n",
      "Epoch: 646..........Loss: 2.386482000350952...........Accuracy: 0.9900000095367432\n",
      "Epoch: 647..........Loss: 29.951200485229492...........Accuracy: 0.9800000190734863\n",
      "Epoch: 648..........Loss: 13.406755447387695...........Accuracy: 0.9800000190734863\n",
      "Epoch: 649..........Loss: 31.648500442504883...........Accuracy: 0.9700000286102295\n",
      "Epoch: 650..........Loss: 67.71661376953125...........Accuracy: 0.9700000286102295\n",
      "Epoch: 651..........Loss: 82.94575500488281...........Accuracy: 0.949999988079071\n",
      "Epoch: 652..........Loss: 104.0482406616211...........Accuracy: 0.949999988079071\n",
      "Epoch: 653..........Loss: 180.42245483398438...........Accuracy: 0.9300000071525574\n",
      "Epoch: 654..........Loss: 87.29859161376953...........Accuracy: 0.949999988079071\n",
      "Epoch: 655..........Loss: 117.46027374267578...........Accuracy: 0.949999988079071\n",
      "Epoch: 656..........Loss: 6.060263633728027...........Accuracy: 0.9900000095367432\n",
      "Epoch: 657..........Loss: 63.131221771240234...........Accuracy: 0.9700000286102295\n",
      "Epoch: 658..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 659..........Loss: 6.290900707244873...........Accuracy: 0.9900000095367432\n",
      "Epoch: 660..........Loss: 40.58283615112305...........Accuracy: 0.9700000286102295\n",
      "Epoch: 661..........Loss: 46.73463439941406...........Accuracy: 0.949999988079071\n",
      "Epoch: 662..........Loss: 67.77062225341797...........Accuracy: 0.9399999976158142\n",
      "Epoch: 663..........Loss: 43.76276397705078...........Accuracy: 0.9800000190734863\n",
      "Epoch: 664..........Loss: 11.091108322143555...........Accuracy: 0.9900000095367432\n",
      "Epoch: 665..........Loss: 72.98555755615234...........Accuracy: 0.9700000286102295\n",
      "Epoch: 666..........Loss: 7.637915134429932...........Accuracy: 0.9900000095367432\n",
      "Epoch: 667..........Loss: 26.668607711791992...........Accuracy: 0.9800000190734863\n",
      "Epoch: 668..........Loss: 71.92269134521484...........Accuracy: 0.9700000286102295\n",
      "Epoch: 669..........Loss: 16.194971084594727...........Accuracy: 0.9800000190734863\n",
      "Epoch: 670..........Loss: 55.26616668701172...........Accuracy: 0.9800000190734863\n",
      "Epoch: 671..........Loss: 111.52765655517578...........Accuracy: 0.949999988079071\n",
      "Epoch: 672..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 673..........Loss: 38.242191314697266...........Accuracy: 0.9800000190734863\n",
      "Epoch: 674..........Loss: 33.96681213378906...........Accuracy: 0.9599999785423279\n",
      "Epoch: 675..........Loss: 13.932416915893555...........Accuracy: 0.9800000190734863\n",
      "Epoch: 676..........Loss: 4.886469841003418...........Accuracy: 0.9900000095367432\n",
      "Epoch: 677..........Loss: 12.306665420532227...........Accuracy: 0.9700000286102295\n",
      "Epoch: 678..........Loss: 9.697333335876465...........Accuracy: 0.9900000095367432\n",
      "Epoch: 679..........Loss: 19.775182723999023...........Accuracy: 0.9700000286102295\n",
      "Epoch: 680..........Loss: 66.25355529785156...........Accuracy: 0.9700000286102295\n",
      "Epoch: 681..........Loss: 5.200873851776123...........Accuracy: 0.9900000095367432\n",
      "Epoch: 682..........Loss: 35.824249267578125...........Accuracy: 0.9599999785423279\n",
      "Epoch: 683..........Loss: 56.362430572509766...........Accuracy: 0.9800000190734863\n",
      "Epoch: 684..........Loss: 13.75607681274414...........Accuracy: 0.9800000190734863\n",
      "Epoch: 685..........Loss: 21.667455673217773...........Accuracy: 0.9900000095367432\n",
      "Epoch: 686..........Loss: 24.149242401123047...........Accuracy: 0.9800000190734863\n",
      "Epoch: 687..........Loss: 30.694177627563477...........Accuracy: 0.9900000095367432\n",
      "Epoch: 688..........Loss: 49.55128479003906...........Accuracy: 0.9300000071525574\n",
      "Epoch: 689..........Loss: 2.8861865997314453...........Accuracy: 0.9900000095367432\n",
      "Epoch: 690..........Loss: 10.408644676208496...........Accuracy: 0.9800000190734863\n",
      "Epoch: 691..........Loss: 98.84109497070312...........Accuracy: 0.9700000286102295\n",
      "Epoch: 692..........Loss: 29.2237548828125...........Accuracy: 0.9700000286102295\n",
      "Epoch: 693..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 694..........Loss: 62.1955451965332...........Accuracy: 0.9599999785423279\n",
      "Epoch: 695..........Loss: 0.5137695074081421...........Accuracy: 0.9900000095367432\n",
      "Epoch: 696..........Loss: 55.313232421875...........Accuracy: 0.949999988079071\n",
      "Epoch: 697..........Loss: 60.9257926940918...........Accuracy: 0.9700000286102295\n",
      "Epoch: 698..........Loss: 163.88345336914062...........Accuracy: 0.9800000190734863\n",
      "Epoch: 699..........Loss: 31.792739868164062...........Accuracy: 0.9800000190734863\n",
      "Epoch: 700..........Loss: 9.784809112548828...........Accuracy: 0.9900000095367432\n",
      "Epoch: 701..........Loss: 26.375221252441406...........Accuracy: 0.9700000286102295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 702..........Loss: 13.321113586425781...........Accuracy: 0.9800000190734863\n",
      "Epoch: 703..........Loss: 32.13568878173828...........Accuracy: 0.9900000095367432\n",
      "Epoch: 704..........Loss: 127.95791625976562...........Accuracy: 0.949999988079071\n",
      "Epoch: 705..........Loss: 40.13371276855469...........Accuracy: 0.9900000095367432\n",
      "Epoch: 706..........Loss: 19.464637756347656...........Accuracy: 0.9900000095367432\n",
      "Epoch: 707..........Loss: 98.21199035644531...........Accuracy: 0.9599999785423279\n",
      "Epoch: 708..........Loss: 56.92123031616211...........Accuracy: 0.9700000286102295\n",
      "Epoch: 709..........Loss: 45.84236145019531...........Accuracy: 0.949999988079071\n",
      "Epoch: 710..........Loss: 16.173364639282227...........Accuracy: 0.9900000095367432\n",
      "Epoch: 711..........Loss: 20.715303421020508...........Accuracy: 0.9800000190734863\n",
      "Epoch: 712..........Loss: 158.83139038085938...........Accuracy: 0.9700000286102295\n",
      "Epoch: 713..........Loss: 25.5776309967041...........Accuracy: 0.9800000190734863\n",
      "Epoch: 714..........Loss: 23.868816375732422...........Accuracy: 0.9800000190734863\n",
      "Epoch: 715..........Loss: 76.0537338256836...........Accuracy: 0.9599999785423279\n",
      "Epoch: 716..........Loss: 7.002905368804932...........Accuracy: 0.9900000095367432\n",
      "Epoch: 717..........Loss: 18.792036056518555...........Accuracy: 0.9800000190734863\n",
      "Epoch: 718..........Loss: 41.77865219116211...........Accuracy: 0.949999988079071\n",
      "Epoch: 719..........Loss: 30.327072143554688...........Accuracy: 0.9700000286102295\n",
      "Epoch: 720..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 721..........Loss: 14.762981414794922...........Accuracy: 0.9900000095367432\n",
      "Epoch: 722..........Loss: 6.947219371795654...........Accuracy: 0.9800000190734863\n",
      "Epoch: 723..........Loss: 116.85961151123047...........Accuracy: 0.9599999785423279\n",
      "Epoch: 724..........Loss: 4.907719612121582...........Accuracy: 0.9700000286102295\n",
      "Epoch: 725..........Loss: 0.6953076124191284...........Accuracy: 0.9900000095367432\n",
      "Epoch: 726..........Loss: 9.813427925109863...........Accuracy: 0.9900000095367432\n",
      "Epoch: 727..........Loss: 53.033565521240234...........Accuracy: 0.9800000190734863\n",
      "Epoch: 728..........Loss: 4.531872749328613...........Accuracy: 0.9900000095367432\n",
      "Epoch: 729..........Loss: 34.66352462768555...........Accuracy: 0.9800000190734863\n",
      "Epoch: 730..........Loss: 82.66378784179688...........Accuracy: 0.9700000286102295\n",
      "Epoch: 731..........Loss: 32.89064025878906...........Accuracy: 0.9800000190734863\n",
      "Epoch: 732..........Loss: 30.922143936157227...........Accuracy: 0.9700000286102295\n",
      "Epoch: 733..........Loss: 55.67105484008789...........Accuracy: 0.9399999976158142\n",
      "Epoch: 734..........Loss: 90.83433532714844...........Accuracy: 0.9900000095367432\n",
      "Epoch: 735..........Loss: 79.99669647216797...........Accuracy: 0.949999988079071\n",
      "Epoch: 736..........Loss: 93.55706024169922...........Accuracy: 0.9599999785423279\n",
      "Epoch: 737..........Loss: 48.409671783447266...........Accuracy: 0.949999988079071\n",
      "Epoch: 738..........Loss: 49.716392517089844...........Accuracy: 0.9300000071525574\n",
      "Epoch: 739..........Loss: 78.15921020507812...........Accuracy: 0.9800000190734863\n",
      "Epoch: 740..........Loss: 11.928767204284668...........Accuracy: 0.9800000190734863\n",
      "Epoch: 741..........Loss: 13.030991554260254...........Accuracy: 0.9900000095367432\n",
      "Epoch: 742..........Loss: 0.9918286204338074...........Accuracy: 0.9900000095367432\n",
      "Epoch: 743..........Loss: 45.77804183959961...........Accuracy: 0.9700000286102295\n",
      "Epoch: 744..........Loss: 31.919851303100586...........Accuracy: 0.9599999785423279\n",
      "Epoch: 745..........Loss: 29.891328811645508...........Accuracy: 0.9800000190734863\n",
      "Epoch: 746..........Loss: 38.20235824584961...........Accuracy: 0.9700000286102295\n",
      "Epoch: 747..........Loss: 105.04296112060547...........Accuracy: 0.9599999785423279\n",
      "Epoch: 748..........Loss: 25.652271270751953...........Accuracy: 0.9800000190734863\n",
      "Epoch: 749..........Loss: 54.90569305419922...........Accuracy: 0.949999988079071\n",
      "Epoch: 750..........Loss: 49.20460891723633...........Accuracy: 0.9900000095367432\n",
      "Epoch: 751..........Loss: 58.088279724121094...........Accuracy: 0.949999988079071\n",
      "Epoch: 752..........Loss: 13.955470085144043...........Accuracy: 0.9700000286102295\n",
      "Epoch: 753..........Loss: 50.637020111083984...........Accuracy: 0.9800000190734863\n",
      "Epoch: 754..........Loss: 1.628115177154541...........Accuracy: 0.9800000190734863\n",
      "Epoch: 755..........Loss: 28.689451217651367...........Accuracy: 0.9800000190734863\n",
      "Epoch: 756..........Loss: 102.7806625366211...........Accuracy: 0.949999988079071\n",
      "Epoch: 757..........Loss: 27.761058807373047...........Accuracy: 0.9700000286102295\n",
      "Epoch: 758..........Loss: 83.44454956054688...........Accuracy: 0.949999988079071\n",
      "Epoch: 759..........Loss: 30.672080993652344...........Accuracy: 0.9800000190734863\n",
      "Epoch: 760..........Loss: 21.620561599731445...........Accuracy: 0.9800000190734863\n",
      "Epoch: 761..........Loss: 41.52809143066406...........Accuracy: 0.949999988079071\n",
      "Epoch: 762..........Loss: 75.65782165527344...........Accuracy: 0.9599999785423279\n",
      "Epoch: 763..........Loss: 105.33273315429688...........Accuracy: 0.9300000071525574\n",
      "Epoch: 764..........Loss: 85.77713012695312...........Accuracy: 0.9700000286102295\n",
      "Epoch: 765..........Loss: 16.561647415161133...........Accuracy: 0.9700000286102295\n",
      "Epoch: 766..........Loss: 38.375831604003906...........Accuracy: 0.9800000190734863\n",
      "Epoch: 767..........Loss: 3.6648778915405273...........Accuracy: 0.9800000190734863\n",
      "Epoch: 768..........Loss: 70.34928894042969...........Accuracy: 0.9700000286102295\n",
      "Epoch: 769..........Loss: 21.118877410888672...........Accuracy: 0.9900000095367432\n",
      "Epoch: 770..........Loss: 9.729941368103027...........Accuracy: 0.9800000190734863\n",
      "Epoch: 771..........Loss: 24.495058059692383...........Accuracy: 0.9800000190734863\n",
      "Epoch: 772..........Loss: 52.2847900390625...........Accuracy: 0.9599999785423279\n",
      "Epoch: 773..........Loss: 65.15377044677734...........Accuracy: 0.9900000095367432\n",
      "Epoch: 774..........Loss: 6.494831562042236...........Accuracy: 0.9800000190734863\n",
      "Epoch: 775..........Loss: 22.734941482543945...........Accuracy: 0.9800000190734863\n",
      "Epoch: 776..........Loss: 40.2652702331543...........Accuracy: 0.9700000286102295\n",
      "Epoch: 777..........Loss: 70.74612426757812...........Accuracy: 0.949999988079071\n",
      "Epoch: 778..........Loss: 44.22227478027344...........Accuracy: 0.9700000286102295\n",
      "Epoch: 779..........Loss: 5.265390396118164...........Accuracy: 0.9900000095367432\n",
      "Epoch: 780..........Loss: 64.06988525390625...........Accuracy: 0.9700000286102295\n",
      "Epoch: 781..........Loss: 28.302143096923828...........Accuracy: 0.9700000286102295\n",
      "Epoch: 782..........Loss: 24.768203735351562...........Accuracy: 0.9900000095367432\n",
      "Epoch: 783..........Loss: 10.582995414733887...........Accuracy: 0.9800000190734863\n",
      "Epoch: 784..........Loss: 70.13894653320312...........Accuracy: 0.9599999785423279\n",
      "Epoch: 785..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 786..........Loss: 53.08574676513672...........Accuracy: 0.9700000286102295\n",
      "Epoch: 787..........Loss: 0.7075097560882568...........Accuracy: 0.9900000095367432\n",
      "Epoch: 788..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 789..........Loss: 34.46238708496094...........Accuracy: 0.9800000190734863\n",
      "Epoch: 790..........Loss: 9.800585746765137...........Accuracy: 0.9900000095367432\n",
      "Epoch: 791..........Loss: 42.1169319152832...........Accuracy: 0.9700000286102295\n",
      "Epoch: 792..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 793..........Loss: 2.9226953983306885...........Accuracy: 0.9900000095367432\n",
      "Epoch: 794..........Loss: 29.30063247680664...........Accuracy: 0.9700000286102295\n",
      "Epoch: 795..........Loss: 3.644960880279541...........Accuracy: 0.9900000095367432\n",
      "Epoch: 796..........Loss: 11.651972770690918...........Accuracy: 0.9800000190734863\n",
      "Epoch: 797..........Loss: 27.95596694946289...........Accuracy: 0.9900000095367432\n",
      "Epoch: 798..........Loss: 53.26030349731445...........Accuracy: 0.949999988079071\n",
      "Epoch: 799..........Loss: 57.154022216796875...........Accuracy: 0.9700000286102295\n",
      "Epoch: 800..........Loss: 77.80912017822266...........Accuracy: 0.9599999785423279\n",
      "Epoch: 801..........Loss: 61.00798416137695...........Accuracy: 0.9900000095367432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 802..........Loss: 77.34992980957031...........Accuracy: 0.9700000286102295\n",
      "Epoch: 803..........Loss: 40.23189926147461...........Accuracy: 0.9800000190734863\n",
      "Epoch: 804..........Loss: 8.770971298217773...........Accuracy: 0.9900000095367432\n",
      "Epoch: 805..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 806..........Loss: 47.573429107666016...........Accuracy: 0.9599999785423279\n",
      "Epoch: 807..........Loss: 36.93024826049805...........Accuracy: 0.949999988079071\n",
      "Epoch: 808..........Loss: 25.1414852142334...........Accuracy: 0.9800000190734863\n",
      "Epoch: 809..........Loss: 44.745452880859375...........Accuracy: 0.9800000190734863\n",
      "Epoch: 810..........Loss: 25.016984939575195...........Accuracy: 0.9700000286102295\n",
      "Epoch: 811..........Loss: 42.140472412109375...........Accuracy: 0.9700000286102295\n",
      "Epoch: 812..........Loss: 58.573341369628906...........Accuracy: 0.949999988079071\n",
      "Epoch: 813..........Loss: 14.98845100402832...........Accuracy: 0.9800000190734863\n",
      "Epoch: 814..........Loss: 25.477128982543945...........Accuracy: 0.9900000095367432\n",
      "Epoch: 815..........Loss: 73.91907501220703...........Accuracy: 0.9700000286102295\n",
      "Epoch: 816..........Loss: 63.95331954956055...........Accuracy: 0.9900000095367432\n",
      "Epoch: 817..........Loss: 86.53982543945312...........Accuracy: 0.9700000286102295\n",
      "Epoch: 818..........Loss: 70.99199676513672...........Accuracy: 0.9700000286102295\n",
      "Epoch: 819..........Loss: 46.21318054199219...........Accuracy: 0.9800000190734863\n",
      "Epoch: 820..........Loss: 35.06355285644531...........Accuracy: 0.9900000095367432\n",
      "Epoch: 821..........Loss: 38.117759704589844...........Accuracy: 0.9900000095367432\n",
      "Epoch: 822..........Loss: 95.77184295654297...........Accuracy: 0.9399999976158142\n",
      "Epoch: 823..........Loss: 55.1186408996582...........Accuracy: 0.9599999785423279\n",
      "Epoch: 824..........Loss: 11.013256072998047...........Accuracy: 0.9800000190734863\n",
      "Epoch: 825..........Loss: 41.48469543457031...........Accuracy: 0.9700000286102295\n",
      "Epoch: 826..........Loss: 44.075828552246094...........Accuracy: 0.9900000095367432\n",
      "Epoch: 827..........Loss: 87.71778106689453...........Accuracy: 0.9700000286102295\n",
      "Epoch: 828..........Loss: 48.258487701416016...........Accuracy: 0.9700000286102295\n",
      "Epoch: 829..........Loss: 18.2841854095459...........Accuracy: 0.9800000190734863\n",
      "Epoch: 830..........Loss: 74.25871276855469...........Accuracy: 0.949999988079071\n",
      "Epoch: 831..........Loss: 35.67401123046875...........Accuracy: 0.9700000286102295\n",
      "Epoch: 832..........Loss: 71.0166015625...........Accuracy: 0.949999988079071\n",
      "Epoch: 833..........Loss: 80.38774108886719...........Accuracy: 0.9800000190734863\n",
      "Epoch: 834..........Loss: 5.874921798706055...........Accuracy: 0.9900000095367432\n",
      "Epoch: 835..........Loss: 2.8611133098602295...........Accuracy: 0.9900000095367432\n",
      "Epoch: 836..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 837..........Loss: 23.871183395385742...........Accuracy: 0.9800000190734863\n",
      "Epoch: 838..........Loss: 71.42998504638672...........Accuracy: 0.9700000286102295\n",
      "Epoch: 839..........Loss: 72.63833618164062...........Accuracy: 0.9700000286102295\n",
      "Epoch: 840..........Loss: 131.09547424316406...........Accuracy: 0.9399999976158142\n",
      "Epoch: 841..........Loss: 22.711109161376953...........Accuracy: 0.9800000190734863\n",
      "Epoch: 842..........Loss: 48.129180908203125...........Accuracy: 0.9800000190734863\n",
      "Epoch: 843..........Loss: 152.81085205078125...........Accuracy: 0.8700000047683716\n",
      "Epoch: 844..........Loss: 48.12092590332031...........Accuracy: 0.9700000286102295\n",
      "Epoch: 845..........Loss: 34.63923645019531...........Accuracy: 0.9900000095367432\n",
      "Epoch: 846..........Loss: 1.3070508241653442...........Accuracy: 0.9900000095367432\n",
      "Epoch: 847..........Loss: 116.00524139404297...........Accuracy: 0.9300000071525574\n",
      "Epoch: 848..........Loss: 70.91492462158203...........Accuracy: 0.9599999785423279\n",
      "Epoch: 849..........Loss: 3.1059277057647705...........Accuracy: 0.9900000095367432\n",
      "Epoch: 850..........Loss: 169.95648193359375...........Accuracy: 0.9399999976158142\n",
      "Epoch: 851..........Loss: 18.78897476196289...........Accuracy: 0.9800000190734863\n",
      "Epoch: 852..........Loss: 17.792400360107422...........Accuracy: 0.9800000190734863\n",
      "Epoch: 853..........Loss: 23.566099166870117...........Accuracy: 0.9599999785423279\n",
      "Epoch: 854..........Loss: 11.727099418640137...........Accuracy: 0.9900000095367432\n",
      "Epoch: 855..........Loss: 23.20757293701172...........Accuracy: 0.9900000095367432\n",
      "Epoch: 856..........Loss: 14.3641996383667...........Accuracy: 0.9900000095367432\n",
      "Epoch: 857..........Loss: 41.90874099731445...........Accuracy: 0.9700000286102295\n",
      "Epoch: 858..........Loss: 24.486783981323242...........Accuracy: 0.9900000095367432\n",
      "Epoch: 859..........Loss: 32.47773361206055...........Accuracy: 0.9399999976158142\n",
      "Epoch: 860..........Loss: 1.0206201076507568...........Accuracy: 0.9900000095367432\n",
      "Epoch: 861..........Loss: 86.11812591552734...........Accuracy: 0.9700000286102295\n",
      "Epoch: 862..........Loss: 39.031036376953125...........Accuracy: 0.9700000286102295\n",
      "Epoch: 863..........Loss: 16.34455108642578...........Accuracy: 0.9800000190734863\n",
      "Epoch: 864..........Loss: 23.370800018310547...........Accuracy: 0.9700000286102295\n",
      "Epoch: 865..........Loss: 52.81538009643555...........Accuracy: 0.9599999785423279\n",
      "Epoch: 866..........Loss: 41.634422302246094...........Accuracy: 0.949999988079071\n",
      "Epoch: 867..........Loss: 24.587907791137695...........Accuracy: 0.9800000190734863\n",
      "Epoch: 868..........Loss: 9.418832778930664...........Accuracy: 0.9800000190734863\n",
      "Epoch: 869..........Loss: 9.138215065002441...........Accuracy: 0.9800000190734863\n",
      "Epoch: 870..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 871..........Loss: 9.370048522949219...........Accuracy: 0.9800000190734863\n",
      "Epoch: 872..........Loss: 60.00299835205078...........Accuracy: 0.9800000190734863\n",
      "Epoch: 873..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 874..........Loss: 76.35076904296875...........Accuracy: 0.949999988079071\n",
      "Epoch: 875..........Loss: 32.293949127197266...........Accuracy: 0.9599999785423279\n",
      "Epoch: 876..........Loss: 126.53158569335938...........Accuracy: 0.9700000286102295\n",
      "Epoch: 877..........Loss: 43.07090377807617...........Accuracy: 0.9800000190734863\n",
      "Epoch: 878..........Loss: 70.08372497558594...........Accuracy: 0.9800000190734863\n",
      "Epoch: 879..........Loss: 48.733219146728516...........Accuracy: 0.9800000190734863\n",
      "Epoch: 880..........Loss: 27.524995803833008...........Accuracy: 0.9800000190734863\n",
      "Epoch: 881..........Loss: 55.012020111083984...........Accuracy: 0.9599999785423279\n",
      "Epoch: 882..........Loss: 41.745201110839844...........Accuracy: 0.9700000286102295\n",
      "Epoch: 883..........Loss: 22.78470230102539...........Accuracy: 0.9700000286102295\n",
      "Epoch: 884..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 885..........Loss: 20.445274353027344...........Accuracy: 0.9900000095367432\n",
      "Epoch: 886..........Loss: 56.559410095214844...........Accuracy: 0.9700000286102295\n",
      "Epoch: 887..........Loss: 14.191484451293945...........Accuracy: 0.9700000286102295\n",
      "Epoch: 888..........Loss: 146.08985900878906...........Accuracy: 0.9599999785423279\n",
      "Epoch: 889..........Loss: 13.213935852050781...........Accuracy: 0.9800000190734863\n",
      "Epoch: 890..........Loss: 47.847808837890625...........Accuracy: 0.9599999785423279\n",
      "Epoch: 891..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 892..........Loss: 135.37156677246094...........Accuracy: 0.949999988079071\n",
      "Epoch: 893..........Loss: 30.13536834716797...........Accuracy: 0.9599999785423279\n",
      "Epoch: 894..........Loss: 132.8123016357422...........Accuracy: 0.949999988079071\n",
      "Epoch: 895..........Loss: 31.586862564086914...........Accuracy: 0.9800000190734863\n",
      "Epoch: 896..........Loss: 32.081974029541016...........Accuracy: 0.9599999785423279\n",
      "Epoch: 897..........Loss: 23.06145477294922...........Accuracy: 0.9800000190734863\n",
      "Epoch: 898..........Loss: 50.57814025878906...........Accuracy: 0.949999988079071\n",
      "Epoch: 899..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 900..........Loss: 111.06731414794922...........Accuracy: 0.9599999785423279\n",
      "Epoch: 901..........Loss: 34.093387603759766...........Accuracy: 0.9800000190734863\n",
      "Epoch: 902..........Loss: 14.935620307922363...........Accuracy: 0.9800000190734863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 903..........Loss: 52.83504867553711...........Accuracy: 0.9800000190734863\n",
      "Epoch: 904..........Loss: 51.086769104003906...........Accuracy: 0.9399999976158142\n",
      "Epoch: 905..........Loss: 65.40782165527344...........Accuracy: 0.9800000190734863\n",
      "Epoch: 906..........Loss: 15.455192565917969...........Accuracy: 0.9800000190734863\n",
      "Epoch: 907..........Loss: 61.83884811401367...........Accuracy: 0.9700000286102295\n",
      "Epoch: 908..........Loss: 66.4628677368164...........Accuracy: 0.9800000190734863\n",
      "Epoch: 909..........Loss: 2.086604118347168...........Accuracy: 0.9900000095367432\n",
      "Epoch: 910..........Loss: 16.64580535888672...........Accuracy: 0.9800000190734863\n",
      "Epoch: 911..........Loss: 9.9932222366333...........Accuracy: 0.9900000095367432\n",
      "Epoch: 912..........Loss: 30.106889724731445...........Accuracy: 0.9800000190734863\n",
      "Epoch: 913..........Loss: 58.554073333740234...........Accuracy: 0.9700000286102295\n",
      "Epoch: 914..........Loss: 16.65072250366211...........Accuracy: 0.9900000095367432\n",
      "Epoch: 915..........Loss: 39.89094161987305...........Accuracy: 0.9700000286102295\n",
      "Epoch: 916..........Loss: 17.395912170410156...........Accuracy: 0.9800000190734863\n",
      "Epoch: 917..........Loss: 18.488910675048828...........Accuracy: 0.9800000190734863\n",
      "Epoch: 918..........Loss: 41.73646545410156...........Accuracy: 0.9700000286102295\n",
      "Epoch: 919..........Loss: 1.8400170803070068...........Accuracy: 0.9900000095367432\n",
      "Epoch: 920..........Loss: 3.0191967487335205...........Accuracy: 0.9900000095367432\n",
      "Epoch: 921..........Loss: 33.192501068115234...........Accuracy: 0.9700000286102295\n",
      "Epoch: 922..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 923..........Loss: 84.23377990722656...........Accuracy: 0.9599999785423279\n",
      "Epoch: 924..........Loss: 24.14609146118164...........Accuracy: 0.9800000190734863\n",
      "Epoch: 925..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 926..........Loss: 28.454051971435547...........Accuracy: 0.9700000286102295\n",
      "Epoch: 927..........Loss: 37.552978515625...........Accuracy: 0.9800000190734863\n",
      "Epoch: 928..........Loss: 43.219940185546875...........Accuracy: 0.9800000190734863\n",
      "Epoch: 929..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 930..........Loss: 70.12506103515625...........Accuracy: 0.9599999785423279\n",
      "Epoch: 931..........Loss: 18.0891056060791...........Accuracy: 0.9900000095367432\n",
      "Epoch: 932..........Loss: 18.8178653717041...........Accuracy: 0.9800000190734863\n",
      "Epoch: 933..........Loss: 1.579199194908142...........Accuracy: 0.9900000095367432\n",
      "Epoch: 934..........Loss: 40.0367546081543...........Accuracy: 0.9800000190734863\n",
      "Epoch: 935..........Loss: 4.58578634262085...........Accuracy: 0.9900000095367432\n",
      "Epoch: 936..........Loss: 11.761635780334473...........Accuracy: 0.9900000095367432\n",
      "Epoch: 937..........Loss: 38.90937042236328...........Accuracy: 0.9900000095367432\n",
      "Epoch: 938..........Loss: 93.70661926269531...........Accuracy: 0.9700000286102295\n",
      "Epoch: 939..........Loss: 9.903655052185059...........Accuracy: 0.9900000095367432\n",
      "Epoch: 940..........Loss: 89.58512878417969...........Accuracy: 0.949999988079071\n",
      "Epoch: 941..........Loss: 4.3813652992248535...........Accuracy: 0.9900000095367432\n",
      "Epoch: 942..........Loss: 6.281743049621582...........Accuracy: 0.9900000095367432\n",
      "Epoch: 943..........Loss: 48.816287994384766...........Accuracy: 0.9399999976158142\n",
      "Epoch: 944..........Loss: 83.69560241699219...........Accuracy: 0.9700000286102295\n",
      "Epoch: 945..........Loss: 39.98934555053711...........Accuracy: 0.9599999785423279\n",
      "Epoch: 946..........Loss: 24.04857635498047...........Accuracy: 0.9700000286102295\n",
      "Epoch: 947..........Loss: 35.39951705932617...........Accuracy: 0.9900000095367432\n",
      "Epoch: 948..........Loss: 16.00090980529785...........Accuracy: 0.9800000190734863\n",
      "Epoch: 949..........Loss: 34.604148864746094...........Accuracy: 0.9800000190734863\n",
      "Epoch: 950..........Loss: 24.784629821777344...........Accuracy: 0.9800000190734863\n",
      "Epoch: 951..........Loss: 22.518823623657227...........Accuracy: 0.9900000095367432\n",
      "Epoch: 952..........Loss: 7.711860179901123...........Accuracy: 0.9800000190734863\n",
      "Epoch: 953..........Loss: 17.13530921936035...........Accuracy: 0.9700000286102295\n",
      "Epoch: 954..........Loss: 66.66227722167969...........Accuracy: 0.9700000286102295\n",
      "Epoch: 955..........Loss: 15.696401596069336...........Accuracy: 0.9599999785423279\n",
      "Epoch: 956..........Loss: 35.97281265258789...........Accuracy: 0.9800000190734863\n",
      "Epoch: 957..........Loss: 27.896286010742188...........Accuracy: 0.9800000190734863\n",
      "Epoch: 958..........Loss: 25.805801391601562...........Accuracy: 0.9800000190734863\n",
      "Epoch: 959..........Loss: 31.055644989013672...........Accuracy: 0.9599999785423279\n",
      "Epoch: 960..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 961..........Loss: 14.876703262329102...........Accuracy: 0.9800000190734863\n",
      "Epoch: 962..........Loss: 9.072624206542969...........Accuracy: 0.9700000286102295\n",
      "Epoch: 963..........Loss: 60.67072296142578...........Accuracy: 0.9800000190734863\n",
      "Epoch: 964..........Loss: 40.19987106323242...........Accuracy: 0.9800000190734863\n",
      "Epoch: 965..........Loss: 24.017168045043945...........Accuracy: 0.9800000190734863\n",
      "Epoch: 966..........Loss: 31.741344451904297...........Accuracy: 0.9700000286102295\n",
      "Epoch: 967..........Loss: 3.4606616497039795...........Accuracy: 0.9900000095367432\n",
      "Epoch: 968..........Loss: 2.736332893371582...........Accuracy: 0.9900000095367432\n",
      "Epoch: 969..........Loss: 12.937456130981445...........Accuracy: 0.9800000190734863\n",
      "Epoch: 970..........Loss: 3.89739990234375...........Accuracy: 0.9900000095367432\n",
      "Epoch: 971..........Loss: 16.812217712402344...........Accuracy: 0.9599999785423279\n",
      "Epoch: 972..........Loss: 91.39619445800781...........Accuracy: 0.9599999785423279\n",
      "Epoch: 973..........Loss: 4.015297889709473...........Accuracy: 0.9900000095367432\n",
      "Epoch: 974..........Loss: 129.81919860839844...........Accuracy: 0.949999988079071\n",
      "Epoch: 975..........Loss: 15.2445650100708...........Accuracy: 0.9800000190734863\n",
      "Epoch: 976..........Loss: 73.3648452758789...........Accuracy: 0.949999988079071\n",
      "Epoch: 977..........Loss: 35.94289779663086...........Accuracy: 0.949999988079071\n",
      "Epoch: 978..........Loss: 20.548337936401367...........Accuracy: 0.9800000190734863\n",
      "Epoch: 979..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 980..........Loss: 31.068462371826172...........Accuracy: 0.9800000190734863\n",
      "Epoch: 981..........Loss: 49.738258361816406...........Accuracy: 0.9800000190734863\n",
      "Epoch: 982..........Loss: 40.36648178100586...........Accuracy: 0.9800000190734863\n",
      "Epoch: 983..........Loss: 12.326555252075195...........Accuracy: 0.9900000095367432\n",
      "Epoch: 984..........Loss: 49.57444763183594...........Accuracy: 0.9700000286102295\n",
      "Epoch: 985..........Loss: 27.075111389160156...........Accuracy: 0.9800000190734863\n",
      "Epoch: 986..........Loss: 15.240531921386719...........Accuracy: 0.9700000286102295\n",
      "Epoch: 987..........Loss: 3.0639843940734863...........Accuracy: 0.9900000095367432\n",
      "Epoch: 988..........Loss: 40.44352722167969...........Accuracy: 0.9800000190734863\n",
      "Epoch: 989..........Loss: 19.736217498779297...........Accuracy: 0.9900000095367432\n",
      "Epoch: 990..........Loss: 60.52638244628906...........Accuracy: 0.949999988079071\n",
      "Epoch: 991..........Loss: 13.123156547546387...........Accuracy: 0.9700000286102295\n",
      "Epoch: 992..........Loss: 31.675861358642578...........Accuracy: 0.9700000286102295\n",
      "Epoch: 993..........Loss: 61.587120056152344...........Accuracy: 0.949999988079071\n",
      "Epoch: 994..........Loss: 0.0...........Accuracy: 1.0\n",
      "Epoch: 995..........Loss: 30.844175338745117...........Accuracy: 0.9700000286102295\n",
      "Epoch: 996..........Loss: 53.5679931640625...........Accuracy: 0.9700000286102295\n",
      "Epoch: 997..........Loss: 9.195233345031738...........Accuracy: 0.9800000190734863\n",
      "Epoch: 998..........Loss: 16.694257736206055...........Accuracy: 0.9900000095367432\n",
      "Epoch: 999..........Loss: 20.76935577392578...........Accuracy: 0.9900000095367432\n",
      "Epoch: 1000..........Loss: 0.0...........Accuracy: 1.0\n",
      "Overall Accuracy: 0.9609375\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        sess.run(optimizer, feed_dict={X: batch_xs, Y: batch_ys, keep_prob: 0.8})\n",
    "        loss_, accuracy_ = sess.run([loss, accuracy], feed_dict={X: batch_xs,\n",
    "                                                                 Y: batch_ys,\n",
    "                                                                 keep_prob: 1.0})\n",
    "        print(\"Epoch: {}..........Loss: {}...........Accuracy: {}\".format(epoch+1, loss_, accuracy_))\n",
    "        \n",
    "    print(\"Overall Accuracy: {}\".format(sess.run(accuracy, feed_dict={X: mnist.test.images[:256],\n",
    "                                                                      Y: mnist.test.labels[:256],\n",
    "                                                                      keep_prob: 1.0})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-69368c361cc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs)\u001b[0m\n\u001b[1;32m   1448\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[1;32m   1449\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1450\u001b[0;31m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1452\u001b[0m         \u001b[0mmodel_checkpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1073\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1075\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1076\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1077\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "saver.save(sess, 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
